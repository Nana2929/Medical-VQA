NAME: 'QCR.CLIPRN50.AE.ROCO.VQARAD.16batchsize.200epoch.withTFIDF.nondeterministic'
OUTPUT_DIR: './output/qcr/pubmedclipRN50_ae/roco/VQARAD'
CPU_MODE: False
SEED: 88

DATASET:
  DATASET: "RAD"
  DATA_DIR: "/home/nanaeilish/projects/mis/PubMedCLIP/QCR_PubMedCLIP/data/data_rad"
  DATA_TYPE: 'jpg'

LOSS:
  LOSS_TYPE: 'BCELogits'

TRAIN:
  BATCH_SIZE: 16
  N_EPOCH: 200
  NUM_WORKERS: 2
  RESUME: False
  INPUT_SNAPSHOT: ""
  OPTIMIZER:
    TYPE: 'ADAMX'
    BASE_LR: 1e-3
    MOMENTUM_CNN: 0.05
    EPS_CNN: 1e-5
  ACTIVATION: 'relu'
  DROPOUT: 0.5
  ATTENTION:
    MODE: 'BAN'
    GLIMPSE: 10
    USE_COUNTER: False
    NUM_STACKS: 2    ## For SAN
  QUESTION:
    RNN: 'GRU'
    LENGTH: 12
    TFIDF: True
    CAT: True
    HID_DIM: 1024   ## Dim of joint semantic features
  VISION:
    V_DIM: 1088    ## Visual input dim : 1024 + 64
    AUTOENCODER: True
    AE_PATH: "pretrained_ae.pth"
    AE_ALPHA: 0.001
    MAML: False
    CLIP: True
    CLIP_PATH: "/home/nanaeilish/projects/mis/PubMedCLIP/PubMedCLIP_RN50.pth"
    CLIP_VISION_ENCODER: "RN50"
    OTHER_MODEL: False


TRANSFORMS:
  TRAIN_TRANSFORMS: ("random_resized_crop", "random_horizontal_flip")
  TEST_TRANSFORMS: ("shorter_resize_for_crop", "center_crop")

TEST:
  BATCH_SIZE: 8
  NUM_WORKERS: 4
  MODEL_FILE: "./output/qcr/pubmedclipRN50_ae/roco/VQARAD/QCR.CLIPRN50.AE.ROCO.VQARAD.16batchsize.200epoch.withTFIDF.nondeterministic/62_best.pth"
  RESULT_DIR: "./results"