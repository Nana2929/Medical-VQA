Sun, 04 Jun 2023 04:22:43 INFO >>>The net is:
Sun, 04 Jun 2023 04:22:43 INFO BAN_Model(
  (w_emb): WordEmbedding(
    (emb): Embedding(1178, 300, padding_idx=1177)
    (emb_): Embedding(1178, 300, padding_idx=1177)
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (q_emb): QuestionEmbedding(
    (rnn): GRU(600, 1024, batch_first=True)
  )
  (close_att): BiAttention(
    (logits): BCNet(
      (v_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=576, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (q_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
      (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    )
  )
  (close_resnet): BiResNet(
    (b_net): ModuleList(
      (0): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (1): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (2): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (3): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (4): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (5): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (6): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (7): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (8): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (9): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (q_prj): ModuleList(
      (0): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (1): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (2): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (3): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (4): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (5): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (6): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (7): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (8): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (9): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
    )
    (c_prj): ModuleList()
  )
  (close_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=1024, out_features=2048, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=2048, out_features=56, bias=True)
    )
  )
  (open_att): BiAttention(
    (logits): BCNet(
      (v_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=576, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (q_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
      (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    )
  )
  (open_resnet): BiResNet(
    (b_net): ModuleList(
      (0): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (1): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (2): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (3): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (4): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (5): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (6): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (7): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (8): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (9): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (q_prj): ModuleList(
      (0): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (1): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (2): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (3): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (4): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (5): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (6): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (7): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (8): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (9): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
    )
    (c_prj): ModuleList()
  )
  (open_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=1024, out_features=2048, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=2048, out_features=431, bias=True)
    )
  )
  (bbn_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=2048, out_features=3072, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=3072, out_features=487, bias=True)
    )
  )
  (typeatt): typeAttention(
    (w_emb): WordEmbedding(
      (emb): Embedding(1178, 300, padding_idx=1177)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (q_emb): QuestionEmbedding(
      (rnn): GRU(300, 1024, batch_first=True)
    )
    (q_final): QuestionAttention(
      (tanh_gate): Linear(in_features=1324, out_features=1024, bias=True)
      (sigmoid_gate): Linear(in_features=1324, out_features=1024, bias=True)
      (attn): Linear(in_features=1024, out_features=1, bias=True)
    )
    (f_fc1): Linear(in_features=1024, out_features=2048, bias=True)
    (f_fc2): Linear(in_features=2048, out_features=1024, bias=True)
    (f_fc3): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (ae): Auto_Encoder_Model(
    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (tran_conv1): ConvTranspose2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (tran_conv2): ConvTranspose2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv5): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (convert): Linear(in_features=16384, out_features=64, bias=True)
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
Sun, 04 Jun 2023 04:24:19 INFO -------[Epoch]:0-------
Sun, 04 Jun 2023 04:24:19 INFO [Train] Loss:0.082200 , Train_Acc:30.515667%
Sun, 04 Jun 2023 04:24:19 INFO [Train] Loss_Open:0.004792 , Loss_Close:0.005395%
Sun, 04 Jun 2023 04:24:22 INFO [Validate] Val_Acc:31.707317%  |  Open_ACC:3.867404%   |  Close_ACC:50.370369%
Sun, 04 Jun 2023 04:24:25 INFO [Result] The best acc is 31.707317% at epoch 0
Sun, 04 Jun 2023 04:26:05 INFO -------[Epoch]:1-------
Sun, 04 Jun 2023 04:26:05 INFO [Train] Loss:0.046022 , Train_Acc:35.933422%
Sun, 04 Jun 2023 04:26:05 INFO [Train] Loss_Open:0.002601 , Loss_Close:0.003077%
Sun, 04 Jun 2023 04:26:09 INFO [Validate] Val_Acc:38.802662%  |  Open_ACC:8.333334%   |  Close_ACC:59.040592%
Sun, 04 Jun 2023 04:26:11 INFO [Result] The best acc is 38.802662% at epoch 1
Sun, 04 Jun 2023 04:27:53 INFO -------[Epoch]:2-------
Sun, 04 Jun 2023 04:27:53 INFO [Train] Loss:0.039426 , Train_Acc:43.798958%
Sun, 04 Jun 2023 04:27:53 INFO [Train] Loss_Open:0.002529 , Loss_Close:0.002430%
Sun, 04 Jun 2023 04:27:58 INFO [Validate] Val_Acc:35.476719%  |  Open_ACC:8.888889%   |  Close_ACC:53.136532%
Sun, 04 Jun 2023 04:27:58 INFO [Result] The best acc is 38.802662% at epoch 1
Sun, 04 Jun 2023 04:30:13 INFO -------[Epoch]:3-------
Sun, 04 Jun 2023 04:30:13 INFO [Train] Loss:0.036073 , Train_Acc:47.650131%
Sun, 04 Jun 2023 04:30:13 INFO [Train] Loss_Open:0.002503 , Loss_Close:0.002094%
Sun, 04 Jun 2023 04:30:19 INFO [Validate] Val_Acc:41.685143%  |  Open_ACC:6.077348%   |  Close_ACC:65.555557%
Sun, 04 Jun 2023 04:30:21 INFO [Result] The best acc is 41.685143% at epoch 3
Sun, 04 Jun 2023 04:32:49 INFO -------[Epoch]:4-------
Sun, 04 Jun 2023 04:32:49 INFO [Train] Loss:0.033059 , Train_Acc:49.575718%
Sun, 04 Jun 2023 04:32:49 INFO [Train] Loss_Open:0.002427 , Loss_Close:0.001828%
Sun, 04 Jun 2023 04:32:55 INFO [Validate] Val_Acc:42.793793%  |  Open_ACC:8.333334%   |  Close_ACC:65.682655%
Sun, 04 Jun 2023 04:32:58 INFO [Result] The best acc is 42.793793% at epoch 4
Sun, 04 Jun 2023 04:35:29 INFO -------[Epoch]:5-------
Sun, 04 Jun 2023 04:35:29 INFO [Train] Loss:0.030033 , Train_Acc:52.056137%
Sun, 04 Jun 2023 04:35:29 INFO [Train] Loss_Open:0.002373 , Loss_Close:0.001546%
Sun, 04 Jun 2023 04:35:37 INFO [Validate] Val_Acc:46.341461%  |  Open_ACC:9.392265%   |  Close_ACC:71.111107%
Sun, 04 Jun 2023 04:35:39 INFO [Result] The best acc is 46.341461% at epoch 5
Sun, 04 Jun 2023 04:38:07 INFO -------[Epoch]:6-------
Sun, 04 Jun 2023 04:38:07 INFO [Train] Loss:0.027278 , Train_Acc:54.503918%
Sun, 04 Jun 2023 04:38:07 INFO [Train] Loss_Open:0.002235 , Loss_Close:0.001350%
Sun, 04 Jun 2023 04:38:15 INFO [Validate] Val_Acc:46.563194%  |  Open_ACC:11.049725%   |  Close_ACC:70.370369%
Sun, 04 Jun 2023 04:38:18 INFO [Result] The best acc is 46.563194% at epoch 6
Sun, 04 Jun 2023 04:40:54 INFO -------[Epoch]:7-------
Sun, 04 Jun 2023 04:40:54 INFO [Train] Loss:0.023909 , Train_Acc:56.951698%
Sun, 04 Jun 2023 04:40:54 INFO [Train] Loss_Open:0.002082 , Loss_Close:0.001099%
Sun, 04 Jun 2023 04:41:01 INFO [Validate] Val_Acc:47.671841%  |  Open_ACC:12.777778%   |  Close_ACC:70.848709%
Sun, 04 Jun 2023 04:41:03 INFO [Result] The best acc is 47.671841% at epoch 7
Sun, 04 Jun 2023 04:43:40 INFO -------[Epoch]:8-------
Sun, 04 Jun 2023 04:43:40 INFO [Train] Loss:0.022460 , Train_Acc:59.823761%
Sun, 04 Jun 2023 04:43:40 INFO [Train] Loss_Open:0.001942 , Loss_Close:0.001042%
Sun, 04 Jun 2023 04:43:47 INFO [Validate] Val_Acc:49.445675%  |  Open_ACC:15.000000%   |  Close_ACC:72.324722%
Sun, 04 Jun 2023 04:43:49 INFO [Result] The best acc is 49.445675% at epoch 8
Sun, 04 Jun 2023 04:46:24 INFO -------[Epoch]:9-------
Sun, 04 Jun 2023 04:46:24 INFO [Train] Loss:0.018905 , Train_Acc:62.500000%
Sun, 04 Jun 2023 04:46:24 INFO [Train] Loss_Open:0.001770 , Loss_Close:0.000785%
Sun, 04 Jun 2023 04:46:32 INFO [Validate] Val_Acc:51.884701%  |  Open_ACC:16.574587%   |  Close_ACC:75.555557%
Sun, 04 Jun 2023 04:46:34 INFO [Result] The best acc is 51.884701% at epoch 9
Sun, 04 Jun 2023 04:49:08 INFO -------[Epoch]:10-------
Sun, 04 Jun 2023 04:49:08 INFO [Train] Loss:0.017632 , Train_Acc:65.763710%
Sun, 04 Jun 2023 04:49:08 INFO [Train] Loss_Open:0.001618 , Loss_Close:0.000754%
Sun, 04 Jun 2023 04:49:15 INFO [Validate] Val_Acc:52.328159%  |  Open_ACC:18.333334%   |  Close_ACC:74.907753%
Sun, 04 Jun 2023 04:49:17 INFO [Result] The best acc is 52.328159% at epoch 10
Sun, 04 Jun 2023 04:51:59 INFO -------[Epoch]:11-------
Sun, 04 Jun 2023 04:51:59 INFO [Train] Loss:0.015508 , Train_Acc:69.060051%
Sun, 04 Jun 2023 04:51:59 INFO [Train] Loss_Open:0.001440 , Loss_Close:0.000652%
Sun, 04 Jun 2023 04:52:07 INFO [Validate] Val_Acc:52.549889%  |  Open_ACC:20.000000%   |  Close_ACC:74.169746%
Sun, 04 Jun 2023 04:52:09 INFO [Result] The best acc is 52.549889% at epoch 11
Sun, 04 Jun 2023 04:54:45 INFO -------[Epoch]:12-------
Sun, 04 Jun 2023 04:54:45 INFO [Train] Loss:0.012818 , Train_Acc:74.053528%
Sun, 04 Jun 2023 04:54:45 INFO [Train] Loss_Open:0.001285 , Loss_Close:0.000474%
Sun, 04 Jun 2023 04:54:53 INFO [Validate] Val_Acc:55.875832%  |  Open_ACC:21.666668%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 04:54:55 INFO [Result] The best acc is 55.875832% at epoch 12
Sun, 04 Jun 2023 04:57:33 INFO -------[Epoch]:13-------
Sun, 04 Jun 2023 04:57:33 INFO [Train] Loss:0.011013 , Train_Acc:77.578331%
Sun, 04 Jun 2023 04:57:33 INFO [Train] Loss_Open:0.001113 , Loss_Close:0.000401%
Sun, 04 Jun 2023 04:57:41 INFO [Validate] Val_Acc:53.658535%  |  Open_ACC:23.204420%   |  Close_ACC:74.074074%
Sun, 04 Jun 2023 04:57:41 INFO [Result] The best acc is 55.875832% at epoch 12
Sun, 04 Jun 2023 05:00:24 INFO -------[Epoch]:14-------
Sun, 04 Jun 2023 05:00:24 INFO [Train] Loss:0.009172 , Train_Acc:80.874672%
Sun, 04 Jun 2023 05:00:24 INFO [Train] Loss_Open:0.000976 , Loss_Close:0.000300%
Sun, 04 Jun 2023 05:00:31 INFO [Validate] Val_Acc:55.654102%  |  Open_ACC:24.444445%   |  Close_ACC:76.383766%
Sun, 04 Jun 2023 05:00:31 INFO [Result] The best acc is 55.875832% at epoch 12
Sun, 04 Jun 2023 05:03:10 INFO -------[Epoch]:15-------
Sun, 04 Jun 2023 05:03:10 INFO [Train] Loss:0.007509 , Train_Acc:84.693214%
Sun, 04 Jun 2023 05:03:10 INFO [Train] Loss_Open:0.000821 , Loss_Close:0.000231%
Sun, 04 Jun 2023 05:03:18 INFO [Validate] Val_Acc:58.093124%  |  Open_ACC:31.666668%   |  Close_ACC:75.645760%
Sun, 04 Jun 2023 05:03:20 INFO [Result] The best acc is 58.093124% at epoch 15
Sun, 04 Jun 2023 05:06:00 INFO -------[Epoch]:16-------
Sun, 04 Jun 2023 05:06:00 INFO [Train] Loss:0.006391 , Train_Acc:86.716713%
Sun, 04 Jun 2023 05:06:00 INFO [Train] Loss_Open:0.000725 , Loss_Close:0.000178%
Sun, 04 Jun 2023 05:06:07 INFO [Validate] Val_Acc:60.310421%  |  Open_ACC:34.444447%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 05:06:10 INFO [Result] The best acc is 60.310421% at epoch 16
Sun, 04 Jun 2023 05:08:51 INFO -------[Epoch]:17-------
Sun, 04 Jun 2023 05:08:51 INFO [Train] Loss:0.005617 , Train_Acc:89.197128%
Sun, 04 Jun 2023 05:08:51 INFO [Train] Loss_Open:0.000623 , Loss_Close:0.000166%
Sun, 04 Jun 2023 05:08:59 INFO [Validate] Val_Acc:58.536587%  |  Open_ACC:33.149174%   |  Close_ACC:75.555557%
Sun, 04 Jun 2023 05:08:59 INFO [Result] The best acc is 60.310421% at epoch 16
Sun, 04 Jun 2023 05:11:37 INFO -------[Epoch]:18-------
Sun, 04 Jun 2023 05:11:37 INFO [Train] Loss:0.005800 , Train_Acc:90.404701%
Sun, 04 Jun 2023 05:11:37 INFO [Train] Loss_Open:0.000560 , Loss_Close:0.000229%
Sun, 04 Jun 2023 05:11:44 INFO [Validate] Val_Acc:61.862526%  |  Open_ACC:41.111111%   |  Close_ACC:75.645760%
Sun, 04 Jun 2023 05:11:47 INFO [Result] The best acc is 61.862526% at epoch 18
Sun, 04 Jun 2023 05:14:28 INFO -------[Epoch]:19-------
Sun, 04 Jun 2023 05:14:28 INFO [Train] Loss:0.004557 , Train_Acc:92.297653%
Sun, 04 Jun 2023 05:14:28 INFO [Train] Loss_Open:0.000434 , Loss_Close:0.000183%
Sun, 04 Jun 2023 05:14:36 INFO [Validate] Val_Acc:65.853661%  |  Open_ACC:45.303867%   |  Close_ACC:79.629631%
Sun, 04 Jun 2023 05:14:38 INFO [Result] The best acc is 65.853661% at epoch 19
Sun, 04 Jun 2023 05:17:18 INFO -------[Epoch]:20-------
Sun, 04 Jun 2023 05:17:18 INFO [Train] Loss:0.004027 , Train_Acc:93.244125%
Sun, 04 Jun 2023 05:17:18 INFO [Train] Loss_Open:0.000392 , Loss_Close:0.000157%
Sun, 04 Jun 2023 05:17:26 INFO [Validate] Val_Acc:63.192905%  |  Open_ACC:42.777779%   |  Close_ACC:76.752769%
Sun, 04 Jun 2023 05:17:26 INFO [Result] The best acc is 65.853661% at epoch 19
Sun, 04 Jun 2023 05:20:07 INFO -------[Epoch]:21-------
Sun, 04 Jun 2023 05:20:07 INFO [Train] Loss:0.003716 , Train_Acc:93.733681%
Sun, 04 Jun 2023 05:20:07 INFO [Train] Loss_Open:0.000349 , Loss_Close:0.000153%
Sun, 04 Jun 2023 05:20:14 INFO [Validate] Val_Acc:65.188469%  |  Open_ACC:46.111111%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 05:20:14 INFO [Result] The best acc is 65.853661% at epoch 19
Sun, 04 Jun 2023 05:22:52 INFO -------[Epoch]:22-------
Sun, 04 Jun 2023 05:22:52 INFO [Train] Loss:0.003150 , Train_Acc:95.006531%
Sun, 04 Jun 2023 05:22:52 INFO [Train] Loss_Open:0.000295 , Loss_Close:0.000130%
Sun, 04 Jun 2023 05:23:00 INFO [Validate] Val_Acc:66.297119%  |  Open_ACC:48.888889%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 05:23:02 INFO [Result] The best acc is 66.297119% at epoch 22
Sun, 04 Jun 2023 05:25:40 INFO -------[Epoch]:23-------
Sun, 04 Jun 2023 05:25:40 INFO [Train] Loss:0.002558 , Train_Acc:95.691910%
Sun, 04 Jun 2023 05:25:40 INFO [Train] Loss_Open:0.000298 , Loss_Close:0.000066%
Sun, 04 Jun 2023 05:25:48 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:50.555557%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 05:25:50 INFO [Result] The best acc is 67.405762% at epoch 23
Sun, 04 Jun 2023 05:28:27 INFO -------[Epoch]:24-------
Sun, 04 Jun 2023 05:28:27 INFO [Train] Loss:0.002818 , Train_Acc:96.573105%
Sun, 04 Jun 2023 05:28:27 INFO [Train] Loss_Open:0.000220 , Loss_Close:0.000147%
Sun, 04 Jun 2023 05:28:34 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:51.111111%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 05:28:34 INFO [Result] The best acc is 67.405762% at epoch 23
Sun, 04 Jun 2023 05:31:14 INFO -------[Epoch]:25-------
Sun, 04 Jun 2023 05:31:14 INFO [Train] Loss:0.002479 , Train_Acc:96.866844%
Sun, 04 Jun 2023 05:31:14 INFO [Train] Loss_Open:0.000219 , Loss_Close:0.000111%
Sun, 04 Jun 2023 05:31:22 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:50.000000%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 05:31:22 INFO [Result] The best acc is 67.405762% at epoch 23
Sun, 04 Jun 2023 05:33:58 INFO -------[Epoch]:26-------
Sun, 04 Jun 2023 05:33:58 INFO [Train] Loss:0.002385 , Train_Acc:97.454308%
Sun, 04 Jun 2023 05:33:58 INFO [Train] Loss_Open:0.000190 , Loss_Close:0.000121%
Sun, 04 Jun 2023 05:34:06 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:50.555557%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 05:34:08 INFO [Result] The best acc is 67.627495% at epoch 26
Sun, 04 Jun 2023 05:36:53 INFO -------[Epoch]:27-------
Sun, 04 Jun 2023 05:36:53 INFO [Train] Loss:0.003045 , Train_Acc:96.540474%
Sun, 04 Jun 2023 05:36:53 INFO [Train] Loss_Open:0.000211 , Loss_Close:0.000177%
Sun, 04 Jun 2023 05:36:59 INFO [Validate] Val_Acc:67.184036%  |  Open_ACC:51.111111%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 05:36:59 INFO [Result] The best acc is 67.627495% at epoch 26
Sun, 04 Jun 2023 05:39:43 INFO -------[Epoch]:28-------
Sun, 04 Jun 2023 05:39:43 INFO [Train] Loss:0.002002 , Train_Acc:97.519585%
Sun, 04 Jun 2023 05:39:43 INFO [Train] Loss_Open:0.000179 , Loss_Close:0.000088%
Sun, 04 Jun 2023 05:39:50 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:51.111111%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 05:39:52 INFO [Result] The best acc is 67.849220% at epoch 28
Sun, 04 Jun 2023 05:42:30 INFO -------[Epoch]:29-------
Sun, 04 Jun 2023 05:42:30 INFO [Train] Loss:0.001336 , Train_Acc:97.845955%
Sun, 04 Jun 2023 05:42:30 INFO [Train] Loss_Open:0.000137 , Loss_Close:0.000047%
Sun, 04 Jun 2023 05:42:36 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:50.555557%   |  Close_ACC:80.073799%
Sun, 04 Jun 2023 05:42:39 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 05:45:18 INFO -------[Epoch]:30-------
Sun, 04 Jun 2023 05:45:18 INFO [Train] Loss:0.001280 , Train_Acc:98.041779%
Sun, 04 Jun 2023 05:45:18 INFO [Train] Loss_Open:0.000132 , Loss_Close:0.000045%
Sun, 04 Jun 2023 05:45:26 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:49.444447%   |  Close_ACC:79.704796%
Sun, 04 Jun 2023 05:45:26 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 05:48:09 INFO -------[Epoch]:31-------
Sun, 04 Jun 2023 05:48:09 INFO [Train] Loss:0.001608 , Train_Acc:98.009140%
Sun, 04 Jun 2023 05:48:09 INFO [Train] Loss_Open:0.000134 , Loss_Close:0.000078%
Sun, 04 Jun 2023 05:48:17 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:49.444447%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 05:48:17 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 05:50:57 INFO -------[Epoch]:32-------
Sun, 04 Jun 2023 05:50:57 INFO [Train] Loss:0.001538 , Train_Acc:97.976501%
Sun, 04 Jun 2023 05:50:57 INFO [Train] Loss_Open:0.000156 , Loss_Close:0.000055%
Sun, 04 Jun 2023 05:51:04 INFO [Validate] Val_Acc:64.523277%  |  Open_ACC:46.666668%   |  Close_ACC:76.383766%
Sun, 04 Jun 2023 05:51:04 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 05:53:42 INFO -------[Epoch]:33-------
Sun, 04 Jun 2023 05:53:42 INFO [Train] Loss:0.001404 , Train_Acc:97.976501%
Sun, 04 Jun 2023 05:53:42 INFO [Train] Loss_Open:0.000127 , Loss_Close:0.000061%
Sun, 04 Jun 2023 05:53:49 INFO [Validate] Val_Acc:66.297119%  |  Open_ACC:48.618786%   |  Close_ACC:78.148148%
Sun, 04 Jun 2023 05:53:49 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 05:56:33 INFO -------[Epoch]:34-------
Sun, 04 Jun 2023 05:56:33 INFO [Train] Loss:0.001907 , Train_Acc:98.302872%
Sun, 04 Jun 2023 05:56:33 INFO [Train] Loss_Open:0.000110 , Loss_Close:0.000126%
Sun, 04 Jun 2023 05:56:41 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:50.000000%   |  Close_ACC:79.335793%
Sun, 04 Jun 2023 05:56:41 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 05:59:25 INFO -------[Epoch]:35-------
Sun, 04 Jun 2023 05:59:25 INFO [Train] Loss:0.001325 , Train_Acc:98.041779%
Sun, 04 Jun 2023 05:59:25 INFO [Train] Loss_Open:0.000111 , Loss_Close:0.000064%
Sun, 04 Jun 2023 05:59:33 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:53.333336%   |  Close_ACC:76.014763%
Sun, 04 Jun 2023 05:59:33 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 06:02:16 INFO -------[Epoch]:36-------
Sun, 04 Jun 2023 06:02:16 INFO [Train] Loss:0.001605 , Train_Acc:98.302872%
Sun, 04 Jun 2023 06:02:16 INFO [Train] Loss_Open:0.000088 , Loss_Close:0.000109%
Sun, 04 Jun 2023 06:02:24 INFO [Validate] Val_Acc:64.079819%  |  Open_ACC:50.276245%   |  Close_ACC:73.333328%
Sun, 04 Jun 2023 06:02:24 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 06:05:07 INFO -------[Epoch]:37-------
Sun, 04 Jun 2023 06:05:07 INFO [Train] Loss:0.001341 , Train_Acc:98.335510%
Sun, 04 Jun 2023 06:05:07 INFO [Train] Loss_Open:0.000101 , Loss_Close:0.000072%
Sun, 04 Jun 2023 06:05:15 INFO [Validate] Val_Acc:65.853661%  |  Open_ACC:49.444447%   |  Close_ACC:76.752769%
Sun, 04 Jun 2023 06:05:15 INFO [Result] The best acc is 68.292679% at epoch 29
Sun, 04 Jun 2023 06:07:56 INFO -------[Epoch]:38-------
Sun, 04 Jun 2023 06:07:56 INFO [Train] Loss:0.001312 , Train_Acc:98.563972%
Sun, 04 Jun 2023 06:07:56 INFO [Train] Loss_Open:0.000076 , Loss_Close:0.000086%
Sun, 04 Jun 2023 06:08:04 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:55.248619%   |  Close_ACC:77.407410%
Sun, 04 Jun 2023 06:08:06 INFO [Result] The best acc is 68.514412% at epoch 38
Sun, 04 Jun 2023 06:10:43 INFO -------[Epoch]:39-------
Sun, 04 Jun 2023 06:10:43 INFO [Train] Loss:0.001353 , Train_Acc:98.368149%
Sun, 04 Jun 2023 06:10:43 INFO [Train] Loss_Open:0.000069 , Loss_Close:0.000095%
Sun, 04 Jun 2023 06:10:51 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:53.333336%   |  Close_ACC:77.121773%
Sun, 04 Jun 2023 06:10:51 INFO [Result] The best acc is 68.514412% at epoch 38
Sun, 04 Jun 2023 06:13:24 INFO -------[Epoch]:40-------
Sun, 04 Jun 2023 06:13:24 INFO [Train] Loss:0.001156 , Train_Acc:98.531334%
Sun, 04 Jun 2023 06:13:24 INFO [Train] Loss_Open:0.000103 , Loss_Close:0.000051%
Sun, 04 Jun 2023 06:13:32 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:50.828732%   |  Close_ACC:78.888885%
Sun, 04 Jun 2023 06:13:32 INFO [Result] The best acc is 68.514412% at epoch 38
Sun, 04 Jun 2023 06:16:05 INFO -------[Epoch]:41-------
Sun, 04 Jun 2023 06:16:05 INFO [Train] Loss:0.000773 , Train_Acc:98.531334%
Sun, 04 Jun 2023 06:16:05 INFO [Train] Loss_Open:0.000073 , Loss_Close:0.000031%
Sun, 04 Jun 2023 06:16:12 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:48.333336%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 06:16:12 INFO [Result] The best acc is 68.514412% at epoch 38
Sun, 04 Jun 2023 06:18:45 INFO -------[Epoch]:42-------
Sun, 04 Jun 2023 06:18:45 INFO [Train] Loss:0.000706 , Train_Acc:98.727158%
Sun, 04 Jun 2023 06:18:45 INFO [Train] Loss_Open:0.000068 , Loss_Close:0.000028%
Sun, 04 Jun 2023 06:18:52 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:50.828732%   |  Close_ACC:78.518517%
Sun, 04 Jun 2023 06:18:52 INFO [Result] The best acc is 68.514412% at epoch 38
Sun, 04 Jun 2023 06:21:26 INFO -------[Epoch]:43-------
Sun, 04 Jun 2023 06:21:26 INFO [Train] Loss:0.000701 , Train_Acc:98.857704%
Sun, 04 Jun 2023 06:21:26 INFO [Train] Loss_Open:0.000066 , Loss_Close:0.000028%
Sun, 04 Jun 2023 06:21:32 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:53.888889%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 06:21:35 INFO [Result] The best acc is 68.736145% at epoch 43
Sun, 04 Jun 2023 06:24:07 INFO -------[Epoch]:44-------
Sun, 04 Jun 2023 06:24:07 INFO [Train] Loss:0.001623 , Train_Acc:98.792427%
Sun, 04 Jun 2023 06:24:07 INFO [Train] Loss_Open:0.000070 , Loss_Close:0.000123%
Sun, 04 Jun 2023 06:24:14 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:51.111111%   |  Close_ACC:77.121773%
Sun, 04 Jun 2023 06:24:14 INFO [Result] The best acc is 68.736145% at epoch 43
Sun, 04 Jun 2023 06:26:44 INFO -------[Epoch]:45-------
Sun, 04 Jun 2023 06:26:44 INFO [Train] Loss:0.001066 , Train_Acc:98.694519%
Sun, 04 Jun 2023 06:26:44 INFO [Train] Loss_Open:0.000085 , Loss_Close:0.000054%
Sun, 04 Jun 2023 06:26:51 INFO [Validate] Val_Acc:69.844788%  |  Open_ACC:55.000000%   |  Close_ACC:79.704796%
Sun, 04 Jun 2023 06:26:53 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:29:24 INFO -------[Epoch]:46-------
Sun, 04 Jun 2023 06:29:24 INFO [Train] Loss:0.001688 , Train_Acc:98.825066%
Sun, 04 Jun 2023 06:29:24 INFO [Train] Loss_Open:0.000074 , Loss_Close:0.000127%
Sun, 04 Jun 2023 06:29:32 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:55.000000%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 06:29:32 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:32:01 INFO -------[Epoch]:47-------
Sun, 04 Jun 2023 06:32:01 INFO [Train] Loss:0.001048 , Train_Acc:98.433418%
Sun, 04 Jun 2023 06:32:01 INFO [Train] Loss_Open:0.000086 , Loss_Close:0.000051%
Sun, 04 Jun 2023 06:32:09 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:56.666668%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 06:32:09 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:34:48 INFO -------[Epoch]:48-------
Sun, 04 Jun 2023 06:34:48 INFO [Train] Loss:0.001780 , Train_Acc:98.498695%
Sun, 04 Jun 2023 06:34:48 INFO [Train] Loss_Open:0.000072 , Loss_Close:0.000138%
Sun, 04 Jun 2023 06:34:56 INFO [Validate] Val_Acc:69.844788%  |  Open_ACC:58.333336%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 06:34:56 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:37:29 INFO -------[Epoch]:49-------
Sun, 04 Jun 2023 06:37:29 INFO [Train] Loss:0.001378 , Train_Acc:98.727158%
Sun, 04 Jun 2023 06:37:29 INFO [Train] Loss_Open:0.000058 , Loss_Close:0.000105%
Sun, 04 Jun 2023 06:37:37 INFO [Validate] Val_Acc:66.518845%  |  Open_ACC:52.777779%   |  Close_ACC:75.645760%
Sun, 04 Jun 2023 06:37:37 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:40:16 INFO -------[Epoch]:50-------
Sun, 04 Jun 2023 06:40:16 INFO [Train] Loss:0.001036 , Train_Acc:98.825066%
Sun, 04 Jun 2023 06:40:16 INFO [Train] Loss_Open:0.000045 , Loss_Close:0.000078%
Sun, 04 Jun 2023 06:40:23 INFO [Validate] Val_Acc:68.070953%  |  Open_ACC:55.248619%   |  Close_ACC:76.666664%
Sun, 04 Jun 2023 06:40:23 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:43:05 INFO -------[Epoch]:51-------
Sun, 04 Jun 2023 06:43:05 INFO [Train] Loss:0.001553 , Train_Acc:98.759796%
Sun, 04 Jun 2023 06:43:05 INFO [Train] Loss_Open:0.000057 , Loss_Close:0.000125%
Sun, 04 Jun 2023 06:43:13 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:54.444447%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 06:43:13 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:45:56 INFO -------[Epoch]:52-------
Sun, 04 Jun 2023 06:45:56 INFO [Train] Loss:0.001177 , Train_Acc:98.661880%
Sun, 04 Jun 2023 06:45:56 INFO [Train] Loss_Open:0.000051 , Loss_Close:0.000089%
Sun, 04 Jun 2023 06:46:02 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:52.777779%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 06:46:02 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:48:45 INFO -------[Epoch]:53-------
Sun, 04 Jun 2023 06:48:45 INFO [Train] Loss:0.001877 , Train_Acc:98.727158%
Sun, 04 Jun 2023 06:48:45 INFO [Train] Loss_Open:0.000043 , Loss_Close:0.000168%
Sun, 04 Jun 2023 06:48:53 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:54.444447%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 06:48:53 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:51:35 INFO -------[Epoch]:54-------
Sun, 04 Jun 2023 06:51:35 INFO [Train] Loss:0.000551 , Train_Acc:99.053528%
Sun, 04 Jun 2023 06:51:35 INFO [Train] Loss_Open:0.000040 , Loss_Close:0.000030%
Sun, 04 Jun 2023 06:51:43 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:50.828732%   |  Close_ACC:78.888885%
Sun, 04 Jun 2023 06:51:43 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:54:16 INFO -------[Epoch]:55-------
Sun, 04 Jun 2023 06:54:16 INFO [Train] Loss:0.000656 , Train_Acc:98.955612%
Sun, 04 Jun 2023 06:54:16 INFO [Train] Loss_Open:0.000050 , Loss_Close:0.000035%
Sun, 04 Jun 2023 06:54:24 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:52.486191%   |  Close_ACC:79.259254%
Sun, 04 Jun 2023 06:54:24 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:57:02 INFO -------[Epoch]:56-------
Sun, 04 Jun 2023 06:57:02 INFO [Train] Loss:0.000949 , Train_Acc:98.922981%
Sun, 04 Jun 2023 06:57:02 INFO [Train] Loss_Open:0.000077 , Loss_Close:0.000047%
Sun, 04 Jun 2023 06:57:09 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:53.333336%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 06:57:09 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 06:59:41 INFO -------[Epoch]:57-------
Sun, 04 Jun 2023 06:59:41 INFO [Train] Loss:0.002342 , Train_Acc:98.759796%
Sun, 04 Jun 2023 06:59:41 INFO [Train] Loss_Open:0.000046 , Loss_Close:0.000215%
Sun, 04 Jun 2023 06:59:49 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:48.066299%   |  Close_ACC:79.629631%
Sun, 04 Jun 2023 06:59:49 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:02:24 INFO -------[Epoch]:58-------
Sun, 04 Jun 2023 07:02:24 INFO [Train] Loss:0.001001 , Train_Acc:98.629242%
Sun, 04 Jun 2023 07:02:24 INFO [Train] Loss_Open:0.000059 , Loss_Close:0.000065%
Sun, 04 Jun 2023 07:02:32 INFO [Validate] Val_Acc:67.184036%  |  Open_ACC:49.444447%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 07:02:32 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:05:04 INFO -------[Epoch]:59-------
Sun, 04 Jun 2023 07:05:04 INFO [Train] Loss:0.001305 , Train_Acc:98.759796%
Sun, 04 Jun 2023 07:05:04 INFO [Train] Loss_Open:0.000055 , Loss_Close:0.000100%
Sun, 04 Jun 2023 07:05:11 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:52.222225%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 07:05:11 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:07:48 INFO -------[Epoch]:60-------
Sun, 04 Jun 2023 07:07:48 INFO [Train] Loss:0.000601 , Train_Acc:98.825066%
Sun, 04 Jun 2023 07:07:48 INFO [Train] Loss_Open:0.000046 , Loss_Close:0.000032%
Sun, 04 Jun 2023 07:07:56 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:55.248619%   |  Close_ACC:77.037033%
Sun, 04 Jun 2023 07:07:56 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:10:32 INFO -------[Epoch]:61-------
Sun, 04 Jun 2023 07:10:32 INFO [Train] Loss:0.001256 , Train_Acc:98.629242%
Sun, 04 Jun 2023 07:10:32 INFO [Train] Loss_Open:0.000059 , Loss_Close:0.000092%
Sun, 04 Jun 2023 07:10:40 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:54.444447%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 07:10:40 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:13:17 INFO -------[Epoch]:62-------
Sun, 04 Jun 2023 07:13:17 INFO [Train] Loss:0.000532 , Train_Acc:99.020889%
Sun, 04 Jun 2023 07:13:17 INFO [Train] Loss_Open:0.000039 , Loss_Close:0.000029%
Sun, 04 Jun 2023 07:13:25 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:55.248619%   |  Close_ACC:78.148148%
Sun, 04 Jun 2023 07:13:25 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:16:06 INFO -------[Epoch]:63-------
Sun, 04 Jun 2023 07:16:06 INFO [Train] Loss:0.000588 , Train_Acc:99.151436%
Sun, 04 Jun 2023 07:16:06 INFO [Train] Loss_Open:0.000043 , Loss_Close:0.000032%
Sun, 04 Jun 2023 07:16:14 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:52.222225%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 07:16:14 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:18:57 INFO -------[Epoch]:64-------
Sun, 04 Jun 2023 07:18:57 INFO [Train] Loss:0.000702 , Train_Acc:99.053528%
Sun, 04 Jun 2023 07:18:57 INFO [Train] Loss_Open:0.000038 , Loss_Close:0.000048%
Sun, 04 Jun 2023 07:19:05 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:54.696136%   |  Close_ACC:77.777779%
Sun, 04 Jun 2023 07:19:05 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:21:50 INFO -------[Epoch]:65-------
Sun, 04 Jun 2023 07:21:50 INFO [Train] Loss:0.000529 , Train_Acc:98.955612%
Sun, 04 Jun 2023 07:21:50 INFO [Train] Loss_Open:0.000042 , Loss_Close:0.000027%
Sun, 04 Jun 2023 07:21:58 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:55.000000%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 07:21:58 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:24:34 INFO -------[Epoch]:66-------
Sun, 04 Jun 2023 07:24:34 INFO [Train] Loss:0.001078 , Train_Acc:98.661880%
Sun, 04 Jun 2023 07:24:34 INFO [Train] Loss_Open:0.000067 , Loss_Close:0.000067%
Sun, 04 Jun 2023 07:24:41 INFO [Validate] Val_Acc:69.401329%  |  Open_ACC:54.143650%   |  Close_ACC:79.629631%
Sun, 04 Jun 2023 07:24:41 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:27:22 INFO -------[Epoch]:67-------
Sun, 04 Jun 2023 07:27:22 INFO [Train] Loss:0.000542 , Train_Acc:99.053528%
Sun, 04 Jun 2023 07:27:22 INFO [Train] Loss_Open:0.000037 , Loss_Close:0.000031%
Sun, 04 Jun 2023 07:27:30 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:56.666668%   |  Close_ACC:77.121773%
Sun, 04 Jun 2023 07:27:30 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:30:09 INFO -------[Epoch]:68-------
Sun, 04 Jun 2023 07:30:09 INFO [Train] Loss:0.000664 , Train_Acc:99.151436%
Sun, 04 Jun 2023 07:30:09 INFO [Train] Loss_Open:0.000031 , Loss_Close:0.000048%
Sun, 04 Jun 2023 07:30:17 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:55.000000%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 07:30:17 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:32:55 INFO -------[Epoch]:69-------
Sun, 04 Jun 2023 07:32:55 INFO [Train] Loss:0.001136 , Train_Acc:98.825066%
Sun, 04 Jun 2023 07:32:55 INFO [Train] Loss_Open:0.000039 , Loss_Close:0.000093%
Sun, 04 Jun 2023 07:33:03 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:55.555557%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 07:33:03 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:35:35 INFO -------[Epoch]:70-------
Sun, 04 Jun 2023 07:35:35 INFO [Train] Loss:0.000528 , Train_Acc:99.086166%
Sun, 04 Jun 2023 07:35:35 INFO [Train] Loss_Open:0.000039 , Loss_Close:0.000029%
Sun, 04 Jun 2023 07:35:41 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:55.865921%   |  Close_ACC:77.573532%
Sun, 04 Jun 2023 07:35:41 INFO [Result] The best acc is 69.844788% at epoch 45
Sun, 04 Jun 2023 07:38:13 INFO -------[Epoch]:71-------
Sun, 04 Jun 2023 07:38:13 INFO [Train] Loss:0.000558 , Train_Acc:98.988251%
Sun, 04 Jun 2023 07:38:13 INFO [Train] Loss_Open:0.000035 , Loss_Close:0.000035%
Sun, 04 Jun 2023 07:38:21 INFO [Validate] Val_Acc:70.288246%  |  Open_ACC:57.222225%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 07:38:23 INFO [Result] The best acc is 70.288246% at epoch 71
Sun, 04 Jun 2023 07:40:55 INFO -------[Epoch]:72-------
Sun, 04 Jun 2023 07:40:55 INFO [Train] Loss:0.001058 , Train_Acc:98.661880%
Sun, 04 Jun 2023 07:40:55 INFO [Train] Loss_Open:0.000048 , Loss_Close:0.000079%
Sun, 04 Jun 2023 07:41:02 INFO [Validate] Val_Acc:68.070953%  |  Open_ACC:53.888889%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 07:41:02 INFO [Result] The best acc is 70.288246% at epoch 71
Sun, 04 Jun 2023 07:43:41 INFO -------[Epoch]:73-------
Sun, 04 Jun 2023 07:43:41 INFO [Train] Loss:0.000606 , Train_Acc:98.955612%
Sun, 04 Jun 2023 07:43:41 INFO [Train] Loss_Open:0.000033 , Loss_Close:0.000041%
Sun, 04 Jun 2023 07:43:47 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:55.248619%   |  Close_ACC:77.777779%
Sun, 04 Jun 2023 07:43:47 INFO [Result] The best acc is 70.288246% at epoch 71
Sun, 04 Jun 2023 07:46:22 INFO -------[Epoch]:74-------
Sun, 04 Jun 2023 07:46:22 INFO [Train] Loss:0.000436 , Train_Acc:99.053528%
Sun, 04 Jun 2023 07:46:22 INFO [Train] Loss_Open:0.000027 , Loss_Close:0.000027%
Sun, 04 Jun 2023 07:46:30 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:52.222225%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 07:46:30 INFO [Result] The best acc is 70.288246% at epoch 71
Sun, 04 Jun 2023 07:49:06 INFO -------[Epoch]:75-------
Sun, 04 Jun 2023 07:49:06 INFO [Train] Loss:0.000533 , Train_Acc:99.184074%
Sun, 04 Jun 2023 07:49:06 INFO [Train] Loss_Open:0.000037 , Loss_Close:0.000031%
Sun, 04 Jun 2023 07:49:14 INFO [Validate] Val_Acc:69.401329%  |  Open_ACC:56.111111%   |  Close_ACC:78.228783%
Sun, 04 Jun 2023 07:49:14 INFO [Result] The best acc is 70.288246% at epoch 71
Sun, 04 Jun 2023 07:51:52 INFO -------[Epoch]:76-------
Sun, 04 Jun 2023 07:51:52 INFO [Train] Loss:0.000759 , Train_Acc:98.890343%
Sun, 04 Jun 2023 07:51:52 INFO [Train] Loss_Open:0.000049 , Loss_Close:0.000046%
Sun, 04 Jun 2023 07:51:59 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:56.666668%   |  Close_ACC:77.121773%
Sun, 04 Jun 2023 07:51:59 INFO [Result] The best acc is 70.288246% at epoch 71
Sun, 04 Jun 2023 07:54:42 INFO -------[Epoch]:77-------
Sun, 04 Jun 2023 07:54:42 INFO [Train] Loss:0.000558 , Train_Acc:99.118797%
Sun, 04 Jun 2023 07:54:42 INFO [Train] Loss_Open:0.000034 , Loss_Close:0.000035%
Sun, 04 Jun 2023 07:54:50 INFO [Validate] Val_Acc:70.509979%  |  Open_ACC:57.777779%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 07:54:52 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 07:57:33 INFO -------[Epoch]:78-------
Sun, 04 Jun 2023 07:57:33 INFO [Train] Loss:0.000455 , Train_Acc:98.955612%
Sun, 04 Jun 2023 07:57:33 INFO [Train] Loss_Open:0.000030 , Loss_Close:0.000027%
Sun, 04 Jun 2023 07:57:41 INFO [Validate] Val_Acc:69.844788%  |  Open_ACC:57.222225%   |  Close_ACC:78.228783%
Sun, 04 Jun 2023 07:57:41 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:00:24 INFO -------[Epoch]:79-------
Sun, 04 Jun 2023 08:00:24 INFO [Train] Loss:0.000909 , Train_Acc:98.727158%
Sun, 04 Jun 2023 08:00:24 INFO [Train] Loss_Open:0.000047 , Loss_Close:0.000063%
Sun, 04 Jun 2023 08:00:32 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:53.333336%   |  Close_ACC:78.228783%
Sun, 04 Jun 2023 08:00:32 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:03:14 INFO -------[Epoch]:80-------
Sun, 04 Jun 2023 08:03:14 INFO [Train] Loss:0.000588 , Train_Acc:99.053528%
Sun, 04 Jun 2023 08:03:14 INFO [Train] Loss_Open:0.000044 , Loss_Close:0.000032%
Sun, 04 Jun 2023 08:03:22 INFO [Validate] Val_Acc:70.288246%  |  Open_ACC:56.666668%   |  Close_ACC:79.335793%
Sun, 04 Jun 2023 08:03:22 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:06:03 INFO -------[Epoch]:81-------
Sun, 04 Jun 2023 08:06:03 INFO [Train] Loss:0.000505 , Train_Acc:99.118797%
Sun, 04 Jun 2023 08:06:03 INFO [Train] Loss_Open:0.000035 , Loss_Close:0.000029%
Sun, 04 Jun 2023 08:06:10 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:54.696136%   |  Close_ACC:77.777779%
Sun, 04 Jun 2023 08:06:10 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:08:51 INFO -------[Epoch]:82-------
Sun, 04 Jun 2023 08:08:51 INFO [Train] Loss:0.000530 , Train_Acc:99.086166%
Sun, 04 Jun 2023 08:08:51 INFO [Train] Loss_Open:0.000029 , Loss_Close:0.000036%
Sun, 04 Jun 2023 08:08:59 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:55.000000%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 08:08:59 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:11:41 INFO -------[Epoch]:83-------
Sun, 04 Jun 2023 08:11:41 INFO [Train] Loss:0.000470 , Train_Acc:99.086166%
Sun, 04 Jun 2023 08:11:41 INFO [Train] Loss_Open:0.000032 , Loss_Close:0.000028%
Sun, 04 Jun 2023 08:11:47 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:53.591164%   |  Close_ACC:78.518517%
Sun, 04 Jun 2023 08:11:47 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:14:27 INFO -------[Epoch]:84-------
Sun, 04 Jun 2023 08:14:27 INFO [Train] Loss:0.000442 , Train_Acc:99.151436%
Sun, 04 Jun 2023 08:14:27 INFO [Train] Loss_Open:0.000027 , Loss_Close:0.000028%
Sun, 04 Jun 2023 08:14:35 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:55.000000%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 08:14:35 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:17:09 INFO -------[Epoch]:85-------
Sun, 04 Jun 2023 08:17:09 INFO [Train] Loss:0.000583 , Train_Acc:98.955612%
Sun, 04 Jun 2023 08:17:09 INFO [Train] Loss_Open:0.000042 , Loss_Close:0.000033%
Sun, 04 Jun 2023 08:17:17 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:53.038677%   |  Close_ACC:77.777779%
Sun, 04 Jun 2023 08:17:17 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:19:51 INFO -------[Epoch]:86-------
Sun, 04 Jun 2023 08:19:51 INFO [Train] Loss:0.000543 , Train_Acc:99.086166%
Sun, 04 Jun 2023 08:19:51 INFO [Train] Loss_Open:0.000036 , Loss_Close:0.000032%
Sun, 04 Jun 2023 08:19:59 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:53.888889%   |  Close_ACC:78.597786%
Sun, 04 Jun 2023 08:19:59 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:22:30 INFO -------[Epoch]:87-------
Sun, 04 Jun 2023 08:22:30 INFO [Train] Loss:0.000698 , Train_Acc:99.086166%
Sun, 04 Jun 2023 08:22:30 INFO [Train] Loss_Open:0.000023 , Loss_Close:0.000058%
Sun, 04 Jun 2023 08:22:38 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:51.111111%   |  Close_ACC:77.121773%
Sun, 04 Jun 2023 08:22:38 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:25:15 INFO -------[Epoch]:88-------
Sun, 04 Jun 2023 08:25:15 INFO [Train] Loss:0.000585 , Train_Acc:99.151436%
Sun, 04 Jun 2023 08:25:15 INFO [Train] Loss_Open:0.000045 , Loss_Close:0.000030%
Sun, 04 Jun 2023 08:25:23 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:55.801105%   |  Close_ACC:76.666664%
Sun, 04 Jun 2023 08:25:23 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:27:59 INFO -------[Epoch]:89-------
Sun, 04 Jun 2023 08:27:59 INFO [Train] Loss:0.000455 , Train_Acc:99.086166%
Sun, 04 Jun 2023 08:27:59 INFO [Train] Loss_Open:0.000029 , Loss_Close:0.000028%
Sun, 04 Jun 2023 08:28:07 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:54.444447%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 08:28:07 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:30:48 INFO -------[Epoch]:90-------
Sun, 04 Jun 2023 08:30:48 INFO [Train] Loss:0.000459 , Train_Acc:99.086166%
Sun, 04 Jun 2023 08:30:48 INFO [Train] Loss_Open:0.000028 , Loss_Close:0.000029%
Sun, 04 Jun 2023 08:30:54 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:54.444447%   |  Close_ACC:77.490776%
Sun, 04 Jun 2023 08:30:54 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:33:36 INFO -------[Epoch]:91-------
Sun, 04 Jun 2023 08:33:36 INFO [Train] Loss:0.000427 , Train_Acc:99.151436%
Sun, 04 Jun 2023 08:33:36 INFO [Train] Loss_Open:0.000026 , Loss_Close:0.000027%
Sun, 04 Jun 2023 08:33:43 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:53.888889%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 08:33:43 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:36:26 INFO -------[Epoch]:92-------
Sun, 04 Jun 2023 08:36:26 INFO [Train] Loss:0.000419 , Train_Acc:98.955612%
Sun, 04 Jun 2023 08:36:26 INFO [Train] Loss_Open:0.000022 , Loss_Close:0.000029%
Sun, 04 Jun 2023 08:36:33 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:55.248619%   |  Close_ACC:77.777779%
Sun, 04 Jun 2023 08:36:33 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:39:11 INFO -------[Epoch]:93-------
Sun, 04 Jun 2023 08:39:11 INFO [Train] Loss:0.000813 , Train_Acc:99.053528%
Sun, 04 Jun 2023 08:39:11 INFO [Train] Loss_Open:0.000021 , Loss_Close:0.000071%
Sun, 04 Jun 2023 08:39:19 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:55.555557%   |  Close_ACC:76.752769%
Sun, 04 Jun 2023 08:39:19 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:41:56 INFO -------[Epoch]:94-------
Sun, 04 Jun 2023 08:41:56 INFO [Train] Loss:0.001006 , Train_Acc:98.727158%
Sun, 04 Jun 2023 08:41:56 INFO [Train] Loss_Open:0.000048 , Loss_Close:0.000073%
Sun, 04 Jun 2023 08:42:04 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:55.000000%   |  Close_ACC:77.859779%
Sun, 04 Jun 2023 08:42:04 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:44:44 INFO -------[Epoch]:95-------
Sun, 04 Jun 2023 08:44:44 INFO [Train] Loss:0.000495 , Train_Acc:98.988251%
Sun, 04 Jun 2023 08:44:44 INFO [Train] Loss_Open:0.000030 , Loss_Close:0.000032%
Sun, 04 Jun 2023 08:44:52 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:52.777779%   |  Close_ACC:77.121773%
Sun, 04 Jun 2023 08:44:52 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:47:26 INFO -------[Epoch]:96-------
Sun, 04 Jun 2023 08:47:26 INFO [Train] Loss:0.000516 , Train_Acc:99.118797%
Sun, 04 Jun 2023 08:47:26 INFO [Train] Loss_Open:0.000027 , Loss_Close:0.000035%
Sun, 04 Jun 2023 08:47:34 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:54.143650%   |  Close_ACC:78.518517%
Sun, 04 Jun 2023 08:47:34 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:50:08 INFO -------[Epoch]:97-------
Sun, 04 Jun 2023 08:50:08 INFO [Train] Loss:0.000421 , Train_Acc:99.020889%
Sun, 04 Jun 2023 08:50:08 INFO [Train] Loss_Open:0.000019 , Loss_Close:0.000031%
Sun, 04 Jun 2023 08:50:15 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:53.333336%   |  Close_ACC:78.966789%
Sun, 04 Jun 2023 08:50:15 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:52:53 INFO -------[Epoch]:98-------
Sun, 04 Jun 2023 08:52:53 INFO [Train] Loss:0.000560 , Train_Acc:99.184074%
Sun, 04 Jun 2023 08:52:53 INFO [Train] Loss_Open:0.000041 , Loss_Close:0.000031%
Sun, 04 Jun 2023 08:53:00 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:54.143650%   |  Close_ACC:78.888885%
Sun, 04 Jun 2023 08:53:00 INFO [Result] The best acc is 70.509979% at epoch 77
Sun, 04 Jun 2023 08:55:33 INFO -------[Epoch]:99-------
Sun, 04 Jun 2023 08:55:33 INFO [Train] Loss:0.000416 , Train_Acc:99.118797%
Sun, 04 Jun 2023 08:55:33 INFO [Train] Loss_Open:0.000025 , Loss_Close:0.000026%
Sun, 04 Jun 2023 08:55:40 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:52.486191%   |  Close_ACC:77.407410%
Sun, 04 Jun 2023 08:55:40 INFO [Result] The best acc is 70.509979% at epoch 77
