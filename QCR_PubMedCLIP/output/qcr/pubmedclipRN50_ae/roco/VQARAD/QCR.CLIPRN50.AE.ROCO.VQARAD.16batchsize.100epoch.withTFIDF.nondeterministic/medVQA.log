Sat, 03 Jun 2023 00:27:34 INFO >>>The net is:
Sat, 03 Jun 2023 00:27:34 INFO BAN_Model(
  (w_emb): WordEmbedding(
    (emb): Embedding(1178, 300, padding_idx=1177)
    (emb_): Embedding(1178, 300, padding_idx=1177)
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (q_emb): QuestionEmbedding(
    (rnn): GRU(600, 1024, batch_first=True)
  )
  (close_att): BiAttention(
    (logits): BCNet(
      (v_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1088, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (q_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
      (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    )
  )
  (close_resnet): BiResNet(
    (b_net): ModuleList(
      (0): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (1): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (2): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (3): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (4): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (5): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (6): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (7): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (8): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (9): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (q_prj): ModuleList(
      (0): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (1): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (2): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (3): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (4): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (5): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (6): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (7): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (8): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (9): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
    )
    (c_prj): ModuleList()
  )
  (close_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=1024, out_features=2048, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=2048, out_features=56, bias=True)
    )
  )
  (open_att): BiAttention(
    (logits): BCNet(
      (v_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1088, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (q_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
      (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    )
  )
  (open_resnet): BiResNet(
    (b_net): ModuleList(
      (0): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (1): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (2): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (3): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (4): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (5): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (6): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (7): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (8): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (9): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1088, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (q_prj): ModuleList(
      (0): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (1): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (2): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (3): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (4): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (5): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (6): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (7): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (8): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (9): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
    )
    (c_prj): ModuleList()
  )
  (open_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=1024, out_features=2048, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=2048, out_features=431, bias=True)
    )
  )
  (bbn_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=2048, out_features=3072, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=3072, out_features=487, bias=True)
    )
  )
  (typeatt): typeAttention(
    (w_emb): WordEmbedding(
      (emb): Embedding(1178, 300, padding_idx=1177)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (q_emb): QuestionEmbedding(
      (rnn): GRU(300, 1024, batch_first=True)
    )
    (q_final): QuestionAttention(
      (tanh_gate): Linear(in_features=1324, out_features=1024, bias=True)
      (sigmoid_gate): Linear(in_features=1324, out_features=1024, bias=True)
      (attn): Linear(in_features=1024, out_features=1, bias=True)
    )
    (f_fc1): Linear(in_features=1024, out_features=2048, bias=True)
    (f_fc2): Linear(in_features=2048, out_features=1024, bias=True)
    (f_fc3): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (ae): Auto_Encoder_Model(
    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (tran_conv1): ConvTranspose2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (tran_conv2): ConvTranspose2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv5): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (convert): Linear(in_features=16384, out_features=64, bias=True)
  (clip): CLIP(
    (visual): ModifiedResNet(
      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (relu): ReLU(inplace=True)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (avgpool): Identity()
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (attnpool): AttentionPool2d(
        (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
        (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
        (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
        (c_proj): Linear(in_features=2048, out_features=1024, bias=True)
      )
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
Sat, 03 Jun 2023 00:29:35 INFO -------[Epoch]:0-------
Sat, 03 Jun 2023 00:29:35 INFO [Train] Loss:128.283388 , Train_Acc:31.657965%
Sat, 03 Jun 2023 00:29:35 INFO [Train] Loss_Open:2.957851 , Loss_Close:11.506754%
Sat, 03 Jun 2023 00:29:44 INFO [Validate] Val_Acc:31.929047%  |  Open_ACC:2.762431%   |  Close_ACC:51.481480%
Sat, 03 Jun 2023 00:29:47 INFO [Result] The best acc is 31.929047% at epoch 0
Sat, 03 Jun 2023 00:32:39 INFO -------[Epoch]:1-------
Sat, 03 Jun 2023 00:32:39 INFO [Train] Loss:0.044171 , Train_Acc:39.001305%
Sat, 03 Jun 2023 00:32:39 INFO [Train] Loss_Open:0.002580 , Loss_Close:0.002896%
Sat, 03 Jun 2023 00:32:47 INFO [Validate] Val_Acc:42.572063%  |  Open_ACC:8.888889%   |  Close_ACC:64.944649%
Sat, 03 Jun 2023 00:32:51 INFO [Result] The best acc is 42.572063% at epoch 1
Sat, 03 Jun 2023 00:35:54 INFO -------[Epoch]:2-------
Sat, 03 Jun 2023 00:35:54 INFO [Train] Loss:0.039385 , Train_Acc:43.864231%
Sat, 03 Jun 2023 00:35:54 INFO [Train] Loss_Open:0.002552 , Loss_Close:0.002409%
Sat, 03 Jun 2023 00:36:03 INFO [Validate] Val_Acc:43.237251%  |  Open_ACC:6.666667%   |  Close_ACC:67.527679%
Sat, 03 Jun 2023 00:36:05 INFO [Result] The best acc is 43.237251% at epoch 2
Sat, 03 Jun 2023 00:39:13 INFO -------[Epoch]:3-------
Sat, 03 Jun 2023 00:39:13 INFO [Train] Loss:0.036169 , Train_Acc:47.617493%
Sat, 03 Jun 2023 00:39:13 INFO [Train] Loss_Open:0.002504 , Loss_Close:0.002103%
Sat, 03 Jun 2023 00:39:22 INFO [Validate] Val_Acc:42.793793%  |  Open_ACC:7.222222%   |  Close_ACC:66.420662%
Sat, 03 Jun 2023 00:39:22 INFO [Result] The best acc is 43.237251% at epoch 2
Sat, 03 Jun 2023 00:42:33 INFO -------[Epoch]:4-------
Sat, 03 Jun 2023 00:42:33 INFO [Train] Loss:0.032882 , Train_Acc:50.391647%
Sat, 03 Jun 2023 00:42:33 INFO [Train] Loss_Open:0.002418 , Loss_Close:0.001816%
Sat, 03 Jun 2023 00:42:42 INFO [Validate] Val_Acc:42.350330%  |  Open_ACC:8.888889%   |  Close_ACC:64.575645%
Sat, 03 Jun 2023 00:42:42 INFO [Result] The best acc is 43.237251% at epoch 2
Sat, 03 Jun 2023 00:45:55 INFO -------[Epoch]:5-------
Sat, 03 Jun 2023 00:45:55 INFO [Train] Loss:0.030259 , Train_Acc:52.447781%
Sat, 03 Jun 2023 00:45:55 INFO [Train] Loss_Open:0.002294 , Loss_Close:0.001624%
Sat, 03 Jun 2023 00:46:03 INFO [Validate] Val_Acc:44.567627%  |  Open_ACC:10.497238%   |  Close_ACC:67.407410%
Sat, 03 Jun 2023 00:46:05 INFO [Result] The best acc is 44.567627% at epoch 5
Sat, 03 Jun 2023 00:49:17 INFO -------[Epoch]:6-------
Sat, 03 Jun 2023 00:49:17 INFO [Train] Loss:0.026694 , Train_Acc:54.634464%
Sat, 03 Jun 2023 00:49:17 INFO [Train] Loss_Open:0.002161 , Loss_Close:0.001339%
Sat, 03 Jun 2023 00:49:26 INFO [Validate] Val_Acc:48.558758%  |  Open_ACC:13.888889%   |  Close_ACC:71.586716%
Sat, 03 Jun 2023 00:49:28 INFO [Result] The best acc is 48.558758% at epoch 6
Sat, 03 Jun 2023 00:52:42 INFO -------[Epoch]:7-------
Sat, 03 Jun 2023 00:52:42 INFO [Train] Loss:0.022967 , Train_Acc:58.550915%
Sat, 03 Jun 2023 00:52:42 INFO [Train] Loss_Open:0.001995 , Loss_Close:0.001059%
Sat, 03 Jun 2023 00:52:51 INFO [Validate] Val_Acc:51.441242%  |  Open_ACC:13.333334%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 00:52:54 INFO [Result] The best acc is 51.441242% at epoch 7
Sat, 03 Jun 2023 00:56:04 INFO -------[Epoch]:8-------
Sat, 03 Jun 2023 00:56:04 INFO [Train] Loss:0.021306 , Train_Acc:60.313316%
Sat, 03 Jun 2023 00:56:04 INFO [Train] Loss_Open:0.001835 , Loss_Close:0.000993%
Sat, 03 Jun 2023 00:56:14 INFO [Validate] Val_Acc:47.893570%  |  Open_ACC:15.469614%   |  Close_ACC:69.629631%
Sat, 03 Jun 2023 00:56:14 INFO [Result] The best acc is 51.441242% at epoch 7
Sat, 03 Jun 2023 00:59:29 INFO -------[Epoch]:9-------
Sat, 03 Jun 2023 00:59:29 INFO [Train] Loss:0.018617 , Train_Acc:63.838120%
Sat, 03 Jun 2023 00:59:29 INFO [Train] Loss_Open:0.001676 , Loss_Close:0.000818%
Sat, 03 Jun 2023 00:59:37 INFO [Validate] Val_Acc:49.223946%  |  Open_ACC:16.022100%   |  Close_ACC:71.481483%
Sat, 03 Jun 2023 00:59:37 INFO [Result] The best acc is 51.441242% at epoch 7
Sat, 03 Jun 2023 01:02:51 INFO -------[Epoch]:10-------
Sat, 03 Jun 2023 01:02:51 INFO [Train] Loss:0.015950 , Train_Acc:67.917755%
Sat, 03 Jun 2023 01:02:51 INFO [Train] Loss_Open:0.001503 , Loss_Close:0.000655%
Sat, 03 Jun 2023 01:03:00 INFO [Validate] Val_Acc:52.328159%  |  Open_ACC:20.000000%   |  Close_ACC:73.800735%
Sat, 03 Jun 2023 01:03:02 INFO [Result] The best acc is 52.328159% at epoch 10
Sat, 03 Jun 2023 01:06:17 INFO -------[Epoch]:11-------
Sat, 03 Jun 2023 01:06:17 INFO [Train] Loss:0.013162 , Train_Acc:72.780678%
Sat, 03 Jun 2023 01:06:17 INFO [Train] Loss_Open:0.001324 , Loss_Close:0.000484%
Sat, 03 Jun 2023 01:06:25 INFO [Validate] Val_Acc:51.662971%  |  Open_ACC:20.000000%   |  Close_ACC:72.693726%
Sat, 03 Jun 2023 01:06:25 INFO [Result] The best acc is 52.328159% at epoch 10
Sat, 03 Jun 2023 01:09:40 INFO -------[Epoch]:12-------
Sat, 03 Jun 2023 01:09:40 INFO [Train] Loss:0.010807 , Train_Acc:76.631851%
Sat, 03 Jun 2023 01:09:40 INFO [Train] Loss_Open:0.001155 , Loss_Close:0.000350%
Sat, 03 Jun 2023 01:09:49 INFO [Validate] Val_Acc:53.658535%  |  Open_ACC:20.994476%   |  Close_ACC:75.555557%
Sat, 03 Jun 2023 01:09:51 INFO [Result] The best acc is 53.658535% at epoch 12
Sat, 03 Jun 2023 01:13:05 INFO -------[Epoch]:13-------
Sat, 03 Jun 2023 01:13:05 INFO [Train] Loss:0.009178 , Train_Acc:79.406006%
Sat, 03 Jun 2023 01:13:05 INFO [Train] Loss_Open:0.000997 , Loss_Close:0.000286%
Sat, 03 Jun 2023 01:13:14 INFO [Validate] Val_Acc:53.215076%  |  Open_ACC:24.444445%   |  Close_ACC:72.324722%
Sat, 03 Jun 2023 01:13:14 INFO [Result] The best acc is 53.658535% at epoch 12
Sat, 03 Jun 2023 01:16:27 INFO -------[Epoch]:14-------
Sat, 03 Jun 2023 01:16:27 INFO [Train] Loss:0.008891 , Train_Acc:83.681465%
Sat, 03 Jun 2023 01:16:27 INFO [Train] Loss_Open:0.000903 , Loss_Close:0.000321%
Sat, 03 Jun 2023 01:16:36 INFO [Validate] Val_Acc:55.875832%  |  Open_ACC:28.333334%   |  Close_ACC:74.169746%
Sat, 03 Jun 2023 01:16:39 INFO [Result] The best acc is 55.875832% at epoch 14
Sat, 03 Jun 2023 01:19:51 INFO -------[Epoch]:15-------
Sat, 03 Jun 2023 01:19:51 INFO [Train] Loss:0.006396 , Train_Acc:86.814621%
Sat, 03 Jun 2023 01:19:51 INFO [Train] Loss_Open:0.000736 , Loss_Close:0.000171%
Sat, 03 Jun 2023 01:20:00 INFO [Validate] Val_Acc:58.758316%  |  Open_ACC:34.806633%   |  Close_ACC:74.814812%
Sat, 03 Jun 2023 01:20:03 INFO [Result] The best acc is 58.758316% at epoch 15
Sat, 03 Jun 2023 01:23:15 INFO -------[Epoch]:16-------
Sat, 03 Jun 2023 01:23:15 INFO [Train] Loss:0.005467 , Train_Acc:89.164490%
Sat, 03 Jun 2023 01:23:15 INFO [Train] Loss_Open:0.000642 , Loss_Close:0.000138%
Sat, 03 Jun 2023 01:23:23 INFO [Validate] Val_Acc:59.423504%  |  Open_ACC:36.111111%   |  Close_ACC:74.907753%
Sat, 03 Jun 2023 01:23:26 INFO [Result] The best acc is 59.423504% at epoch 16
Sat, 03 Jun 2023 01:26:37 INFO -------[Epoch]:17-------
Sat, 03 Jun 2023 01:26:37 INFO [Train] Loss:0.004479 , Train_Acc:90.633163%
Sat, 03 Jun 2023 01:26:37 INFO [Train] Loss_Open:0.000545 , Loss_Close:0.000100%
Sat, 03 Jun 2023 01:26:45 INFO [Validate] Val_Acc:59.423504%  |  Open_ACC:38.674034%   |  Close_ACC:73.333328%
Sat, 03 Jun 2023 01:26:45 INFO [Result] The best acc is 59.423504% at epoch 16
Sat, 03 Jun 2023 01:30:01 INFO -------[Epoch]:18-------
Sat, 03 Jun 2023 01:30:01 INFO [Train] Loss:0.004549 , Train_Acc:91.416451%
Sat, 03 Jun 2023 01:30:01 INFO [Train] Loss_Open:0.000501 , Loss_Close:0.000137%
Sat, 03 Jun 2023 01:30:10 INFO [Validate] Val_Acc:61.862526%  |  Open_ACC:43.888889%   |  Close_ACC:73.800735%
Sat, 03 Jun 2023 01:30:12 INFO [Result] The best acc is 61.862526% at epoch 18
Sat, 03 Jun 2023 01:33:20 INFO -------[Epoch]:19-------
Sat, 03 Jun 2023 01:33:20 INFO [Train] Loss:0.005083 , Train_Acc:92.819847%
Sat, 03 Jun 2023 01:33:20 INFO [Train] Loss_Open:0.000421 , Loss_Close:0.000248%
Sat, 03 Jun 2023 01:33:29 INFO [Validate] Val_Acc:62.749447%  |  Open_ACC:41.988953%   |  Close_ACC:76.666664%
Sat, 03 Jun 2023 01:33:32 INFO [Result] The best acc is 62.749447% at epoch 19
Sat, 03 Jun 2023 01:36:43 INFO -------[Epoch]:20-------
Sat, 03 Jun 2023 01:36:43 INFO [Train] Loss:0.003803 , Train_Acc:94.288513%
Sat, 03 Jun 2023 01:36:43 INFO [Train] Loss_Open:0.000369 , Loss_Close:0.000148%
Sat, 03 Jun 2023 01:36:52 INFO [Validate] Val_Acc:60.088692%  |  Open_ACC:42.777779%   |  Close_ACC:71.586716%
Sat, 03 Jun 2023 01:36:52 INFO [Result] The best acc is 62.749447% at epoch 19
Sat, 03 Jun 2023 01:40:06 INFO -------[Epoch]:21-------
Sat, 03 Jun 2023 01:40:06 INFO [Train] Loss:0.002923 , Train_Acc:95.039169%
Sat, 03 Jun 2023 01:40:06 INFO [Train] Loss_Open:0.000313 , Loss_Close:0.000094%
Sat, 03 Jun 2023 01:40:15 INFO [Validate] Val_Acc:61.862526%  |  Open_ACC:43.093925%   |  Close_ACC:74.444443%
Sat, 03 Jun 2023 01:40:15 INFO [Result] The best acc is 62.749447% at epoch 19
Sat, 03 Jun 2023 01:43:26 INFO -------[Epoch]:22-------
Sat, 03 Jun 2023 01:43:26 INFO [Train] Loss:0.002747 , Train_Acc:95.528725%
Sat, 03 Jun 2023 01:43:26 INFO [Train] Loss_Open:0.000253 , Loss_Close:0.000116%
Sat, 03 Jun 2023 01:43:35 INFO [Validate] Val_Acc:63.414635%  |  Open_ACC:46.666668%   |  Close_ACC:74.538750%
Sat, 03 Jun 2023 01:43:38 INFO [Result] The best acc is 63.414635% at epoch 22
Sat, 03 Jun 2023 01:46:48 INFO -------[Epoch]:23-------
Sat, 03 Jun 2023 01:46:48 INFO [Train] Loss:0.003412 , Train_Acc:95.691910%
Sat, 03 Jun 2023 01:46:48 INFO [Train] Loss_Open:0.000255 , Loss_Close:0.000185%
Sat, 03 Jun 2023 01:46:57 INFO [Validate] Val_Acc:62.971176%  |  Open_ACC:47.222225%   |  Close_ACC:73.431732%
Sat, 03 Jun 2023 01:46:57 INFO [Result] The best acc is 63.414635% at epoch 22
Sat, 03 Jun 2023 01:50:13 INFO -------[Epoch]:24-------
Sat, 03 Jun 2023 01:50:13 INFO [Train] Loss:0.002713 , Train_Acc:96.181465%
Sat, 03 Jun 2023 01:50:13 INFO [Train] Loss_Open:0.000247 , Loss_Close:0.000117%
Sat, 03 Jun 2023 01:50:22 INFO [Validate] Val_Acc:64.966743%  |  Open_ACC:46.111111%   |  Close_ACC:77.490776%
Sat, 03 Jun 2023 01:50:25 INFO [Result] The best acc is 64.966743% at epoch 24
Sat, 03 Jun 2023 01:53:33 INFO -------[Epoch]:25-------
Sat, 03 Jun 2023 01:53:33 INFO [Train] Loss:0.001792 , Train_Acc:96.834206%
Sat, 03 Jun 2023 01:53:33 INFO [Train] Loss_Open:0.000191 , Loss_Close:0.000058%
Sat, 03 Jun 2023 01:53:41 INFO [Validate] Val_Acc:65.410202%  |  Open_ACC:49.444447%   |  Close_ACC:76.014763%
Sat, 03 Jun 2023 01:53:43 INFO [Result] The best acc is 65.410202% at epoch 25
Sat, 03 Jun 2023 01:56:54 INFO -------[Epoch]:26-------
Sat, 03 Jun 2023 01:56:54 INFO [Train] Loss:0.002410 , Train_Acc:97.258484%
Sat, 03 Jun 2023 01:56:54 INFO [Train] Loss_Open:0.000177 , Loss_Close:0.000133%
Sat, 03 Jun 2023 01:57:03 INFO [Validate] Val_Acc:65.188469%  |  Open_ACC:51.381218%   |  Close_ACC:74.444443%
Sat, 03 Jun 2023 01:57:03 INFO [Result] The best acc is 65.410202% at epoch 25
Sat, 03 Jun 2023 02:00:15 INFO -------[Epoch]:27-------
Sat, 03 Jun 2023 02:00:15 INFO [Train] Loss:0.001825 , Train_Acc:97.030029%
Sat, 03 Jun 2023 02:00:15 INFO [Train] Loss_Open:0.000192 , Loss_Close:0.000061%
Sat, 03 Jun 2023 02:00:24 INFO [Validate] Val_Acc:65.410202%  |  Open_ACC:50.555557%   |  Close_ACC:75.276756%
Sat, 03 Jun 2023 02:00:24 INFO [Result] The best acc is 65.410202% at epoch 25
Sat, 03 Jun 2023 02:03:35 INFO -------[Epoch]:28-------
Sat, 03 Jun 2023 02:03:35 INFO [Train] Loss:0.001654 , Train_Acc:97.389038%
Sat, 03 Jun 2023 02:03:35 INFO [Train] Loss_Open:0.000170 , Loss_Close:0.000058%
Sat, 03 Jun 2023 02:03:44 INFO [Validate] Val_Acc:64.966743%  |  Open_ACC:48.618786%   |  Close_ACC:75.925926%
Sat, 03 Jun 2023 02:03:44 INFO [Result] The best acc is 65.410202% at epoch 25
Sat, 03 Jun 2023 02:06:51 INFO -------[Epoch]:29-------
Sat, 03 Jun 2023 02:06:51 INFO [Train] Loss:0.001452 , Train_Acc:97.780678%
Sat, 03 Jun 2023 02:06:51 INFO [Train] Loss_Open:0.000159 , Loss_Close:0.000044%
Sat, 03 Jun 2023 02:07:00 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:50.828732%   |  Close_ACC:77.777779%
Sat, 03 Jun 2023 02:07:02 INFO [Result] The best acc is 66.962303% at epoch 29
Sat, 03 Jun 2023 02:10:13 INFO -------[Epoch]:30-------
Sat, 03 Jun 2023 02:10:13 INFO [Train] Loss:0.001355 , Train_Acc:98.074417%
Sat, 03 Jun 2023 02:10:13 INFO [Train] Loss_Open:0.000146 , Loss_Close:0.000042%
Sat, 03 Jun 2023 02:10:22 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:53.591164%   |  Close_ACC:75.925926%
Sat, 03 Jun 2023 02:10:22 INFO [Result] The best acc is 66.962303% at epoch 29
Sat, 03 Jun 2023 02:13:34 INFO -------[Epoch]:31-------
Sat, 03 Jun 2023 02:13:34 INFO [Train] Loss:0.002029 , Train_Acc:97.748047%
Sat, 03 Jun 2023 02:13:34 INFO [Train] Loss_Open:0.000161 , Loss_Close:0.000103%
Sat, 03 Jun 2023 02:13:42 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:51.111111%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 02:13:42 INFO [Result] The best acc is 66.962303% at epoch 29
Sat, 03 Jun 2023 02:16:51 INFO -------[Epoch]:32-------
Sat, 03 Jun 2023 02:16:51 INFO [Train] Loss:0.001340 , Train_Acc:98.074417%
Sat, 03 Jun 2023 02:16:51 INFO [Train] Loss_Open:0.000134 , Loss_Close:0.000049%
Sat, 03 Jun 2023 02:17:00 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:52.222225%   |  Close_ACC:77.490776%
Sat, 03 Jun 2023 02:17:03 INFO [Result] The best acc is 67.405762% at epoch 32
Sat, 03 Jun 2023 02:20:12 INFO -------[Epoch]:33-------
Sat, 03 Jun 2023 02:20:12 INFO [Train] Loss:0.000969 , Train_Acc:98.368149%
Sat, 03 Jun 2023 02:20:12 INFO [Train] Loss_Open:0.000104 , Loss_Close:0.000031%
Sat, 03 Jun 2023 02:20:21 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:55.000000%   |  Close_ACC:78.597786%
Sat, 03 Jun 2023 02:20:23 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:23:35 INFO -------[Epoch]:34-------
Sat, 03 Jun 2023 02:23:35 INFO [Train] Loss:0.001006 , Train_Acc:98.531334%
Sat, 03 Jun 2023 02:23:35 INFO [Train] Loss_Open:0.000110 , Loss_Close:0.000031%
Sat, 03 Jun 2023 02:23:44 INFO [Validate] Val_Acc:67.184036%  |  Open_ACC:51.933704%   |  Close_ACC:77.407410%
Sat, 03 Jun 2023 02:23:44 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:26:55 INFO -------[Epoch]:35-------
Sat, 03 Jun 2023 02:26:55 INFO [Train] Loss:0.001786 , Train_Acc:98.237602%
Sat, 03 Jun 2023 02:26:55 INFO [Train] Loss_Open:0.000126 , Loss_Close:0.000102%
Sat, 03 Jun 2023 02:27:04 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:53.038677%   |  Close_ACC:78.888885%
Sat, 03 Jun 2023 02:27:04 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:30:15 INFO -------[Epoch]:36-------
Sat, 03 Jun 2023 02:30:15 INFO [Train] Loss:0.001481 , Train_Acc:98.335510%
Sat, 03 Jun 2023 02:30:15 INFO [Train] Loss_Open:0.000119 , Loss_Close:0.000074%
Sat, 03 Jun 2023 02:30:24 INFO [Validate] Val_Acc:64.966743%  |  Open_ACC:50.828732%   |  Close_ACC:74.444443%
Sat, 03 Jun 2023 02:30:24 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:33:36 INFO -------[Epoch]:37-------
Sat, 03 Jun 2023 02:33:36 INFO [Train] Loss:0.001487 , Train_Acc:98.270233%
Sat, 03 Jun 2023 02:33:36 INFO [Train] Loss_Open:0.000096 , Loss_Close:0.000091%
Sat, 03 Jun 2023 02:33:44 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:55.248619%   |  Close_ACC:75.925926%
Sat, 03 Jun 2023 02:33:44 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:36:55 INFO -------[Epoch]:38-------
Sat, 03 Jun 2023 02:36:55 INFO [Train] Loss:0.001824 , Train_Acc:98.629242%
Sat, 03 Jun 2023 02:36:55 INFO [Train] Loss_Open:0.000083 , Loss_Close:0.000135%
Sat, 03 Jun 2023 02:37:04 INFO [Validate] Val_Acc:65.631927%  |  Open_ACC:50.828732%   |  Close_ACC:75.555557%
Sat, 03 Jun 2023 02:37:04 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:40:13 INFO -------[Epoch]:39-------
Sat, 03 Jun 2023 02:40:13 INFO [Train] Loss:0.000899 , Train_Acc:98.400787%
Sat, 03 Jun 2023 02:40:13 INFO [Train] Loss_Open:0.000077 , Loss_Close:0.000042%
Sat, 03 Jun 2023 02:40:22 INFO [Validate] Val_Acc:68.070953%  |  Open_ACC:52.222225%   |  Close_ACC:78.597786%
Sat, 03 Jun 2023 02:40:22 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:43:35 INFO -------[Epoch]:40-------
Sat, 03 Jun 2023 02:43:35 INFO [Train] Loss:0.001156 , Train_Acc:98.694519%
Sat, 03 Jun 2023 02:43:35 INFO [Train] Loss_Open:0.000061 , Loss_Close:0.000080%
Sat, 03 Jun 2023 02:43:44 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:54.444447%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 02:43:44 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:46:51 INFO -------[Epoch]:41-------
Sat, 03 Jun 2023 02:46:51 INFO [Train] Loss:0.001264 , Train_Acc:98.759796%
Sat, 03 Jun 2023 02:46:51 INFO [Train] Loss_Open:0.000065 , Loss_Close:0.000088%
Sat, 03 Jun 2023 02:47:00 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:54.143650%   |  Close_ACC:78.148148%
Sat, 03 Jun 2023 02:47:00 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:50:12 INFO -------[Epoch]:42-------
Sat, 03 Jun 2023 02:50:12 INFO [Train] Loss:0.000847 , Train_Acc:98.498695%
Sat, 03 Jun 2023 02:50:12 INFO [Train] Loss_Open:0.000074 , Loss_Close:0.000039%
Sat, 03 Jun 2023 02:50:21 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:53.333336%   |  Close_ACC:75.645760%
Sat, 03 Jun 2023 02:50:21 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:53:30 INFO -------[Epoch]:43-------
Sat, 03 Jun 2023 02:53:30 INFO [Train] Loss:0.000870 , Train_Acc:98.400787%
Sat, 03 Jun 2023 02:53:30 INFO [Train] Loss_Open:0.000089 , Loss_Close:0.000030%
Sat, 03 Jun 2023 02:53:39 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:54.444447%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 02:53:39 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 02:56:51 INFO -------[Epoch]:44-------
Sat, 03 Jun 2023 02:56:51 INFO [Train] Loss:0.000895 , Train_Acc:98.694519%
Sat, 03 Jun 2023 02:56:51 INFO [Train] Loss_Open:0.000063 , Loss_Close:0.000051%
Sat, 03 Jun 2023 02:56:59 INFO [Validate] Val_Acc:68.070953%  |  Open_ACC:52.486191%   |  Close_ACC:78.518517%
Sat, 03 Jun 2023 02:56:59 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:00:08 INFO -------[Epoch]:45-------
Sat, 03 Jun 2023 03:00:08 INFO [Train] Loss:0.000722 , Train_Acc:98.759796%
Sat, 03 Jun 2023 03:00:08 INFO [Train] Loss_Open:0.000062 , Loss_Close:0.000034%
Sat, 03 Jun 2023 03:00:17 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:57.777779%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 03:00:17 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:03:25 INFO -------[Epoch]:46-------
Sat, 03 Jun 2023 03:03:25 INFO [Train] Loss:0.001410 , Train_Acc:98.694519%
Sat, 03 Jun 2023 03:03:25 INFO [Train] Loss_Open:0.000064 , Loss_Close:0.000105%
Sat, 03 Jun 2023 03:03:34 INFO [Validate] Val_Acc:68.070953%  |  Open_ACC:56.111111%   |  Close_ACC:76.014763%
Sat, 03 Jun 2023 03:03:34 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:06:42 INFO -------[Epoch]:47-------
Sat, 03 Jun 2023 03:06:42 INFO [Train] Loss:0.001087 , Train_Acc:98.694519%
Sat, 03 Jun 2023 03:06:42 INFO [Train] Loss_Open:0.000067 , Loss_Close:0.000069%
Sat, 03 Jun 2023 03:06:51 INFO [Validate] Val_Acc:66.518845%  |  Open_ACC:55.248619%   |  Close_ACC:74.074074%
Sat, 03 Jun 2023 03:06:51 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:09:58 INFO -------[Epoch]:48-------
Sat, 03 Jun 2023 03:09:58 INFO [Train] Loss:0.000905 , Train_Acc:98.857704%
Sat, 03 Jun 2023 03:09:58 INFO [Train] Loss_Open:0.000061 , Loss_Close:0.000054%
Sat, 03 Jun 2023 03:10:07 INFO [Validate] Val_Acc:67.184036%  |  Open_ACC:54.945057%   |  Close_ACC:75.464684%
Sat, 03 Jun 2023 03:10:07 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:13:15 INFO -------[Epoch]:49-------
Sat, 03 Jun 2023 03:13:15 INFO [Train] Loss:0.001002 , Train_Acc:98.694519%
Sat, 03 Jun 2023 03:13:15 INFO [Train] Loss_Open:0.000050 , Loss_Close:0.000071%
Sat, 03 Jun 2023 03:13:24 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:56.111111%   |  Close_ACC:75.276756%
Sat, 03 Jun 2023 03:13:24 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:16:33 INFO -------[Epoch]:50-------
Sat, 03 Jun 2023 03:16:33 INFO [Train] Loss:0.000760 , Train_Acc:98.563972%
Sat, 03 Jun 2023 03:16:33 INFO [Train] Loss_Open:0.000065 , Loss_Close:0.000035%
Sat, 03 Jun 2023 03:16:42 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:54.143650%   |  Close_ACC:75.185181%
Sat, 03 Jun 2023 03:16:42 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:19:49 INFO -------[Epoch]:51-------
Sat, 03 Jun 2023 03:19:49 INFO [Train] Loss:0.000624 , Train_Acc:98.890343%
Sat, 03 Jun 2023 03:19:49 INFO [Train] Loss_Open:0.000055 , Loss_Close:0.000028%
Sat, 03 Jun 2023 03:19:58 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:56.111111%   |  Close_ACC:75.645760%
Sat, 03 Jun 2023 03:19:58 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:23:07 INFO -------[Epoch]:52-------
Sat, 03 Jun 2023 03:23:07 INFO [Train] Loss:0.001168 , Train_Acc:98.792427%
Sat, 03 Jun 2023 03:23:07 INFO [Train] Loss_Open:0.000054 , Loss_Close:0.000086%
Sat, 03 Jun 2023 03:23:16 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:55.555557%   |  Close_ACC:75.276756%
Sat, 03 Jun 2023 03:23:16 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:26:20 INFO -------[Epoch]:53-------
Sat, 03 Jun 2023 03:26:20 INFO [Train] Loss:0.000683 , Train_Acc:98.890343%
Sat, 03 Jun 2023 03:26:20 INFO [Train] Loss_Open:0.000052 , Loss_Close:0.000036%
Sat, 03 Jun 2023 03:26:28 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:55.000000%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 03:26:28 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:29:39 INFO -------[Epoch]:54-------
Sat, 03 Jun 2023 03:29:39 INFO [Train] Loss:0.000757 , Train_Acc:98.955612%
Sat, 03 Jun 2023 03:29:39 INFO [Train] Loss_Open:0.000054 , Loss_Close:0.000043%
Sat, 03 Jun 2023 03:29:48 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:53.888889%   |  Close_ACC:77.859779%
Sat, 03 Jun 2023 03:29:48 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:32:56 INFO -------[Epoch]:55-------
Sat, 03 Jun 2023 03:32:56 INFO [Train] Loss:0.000762 , Train_Acc:98.890343%
Sat, 03 Jun 2023 03:32:56 INFO [Train] Loss_Open:0.000070 , Loss_Close:0.000032%
Sat, 03 Jun 2023 03:33:05 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:54.444447%   |  Close_ACC:77.490776%
Sat, 03 Jun 2023 03:33:05 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:36:10 INFO -------[Epoch]:56-------
Sat, 03 Jun 2023 03:36:10 INFO [Train] Loss:0.000719 , Train_Acc:99.020889%
Sat, 03 Jun 2023 03:36:10 INFO [Train] Loss_Open:0.000057 , Loss_Close:0.000036%
Sat, 03 Jun 2023 03:36:18 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:54.444447%   |  Close_ACC:76.383766%
Sat, 03 Jun 2023 03:36:18 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:39:27 INFO -------[Epoch]:57-------
Sat, 03 Jun 2023 03:39:27 INFO [Train] Loss:0.000895 , Train_Acc:98.922981%
Sat, 03 Jun 2023 03:39:27 INFO [Train] Loss_Open:0.000053 , Loss_Close:0.000058%
Sat, 03 Jun 2023 03:39:35 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:53.333336%   |  Close_ACC:76.014763%
Sat, 03 Jun 2023 03:39:35 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:42:41 INFO -------[Epoch]:58-------
Sat, 03 Jun 2023 03:42:41 INFO [Train] Loss:0.001047 , Train_Acc:98.890343%
Sat, 03 Jun 2023 03:42:41 INFO [Train] Loss_Open:0.000052 , Loss_Close:0.000075%
Sat, 03 Jun 2023 03:42:50 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:52.777779%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 03:42:50 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:45:56 INFO -------[Epoch]:59-------
Sat, 03 Jun 2023 03:45:56 INFO [Train] Loss:0.000948 , Train_Acc:98.857704%
Sat, 03 Jun 2023 03:45:56 INFO [Train] Loss_Open:0.000046 , Loss_Close:0.000068%
Sat, 03 Jun 2023 03:46:04 INFO [Validate] Val_Acc:66.740578%  |  Open_ACC:55.000000%   |  Close_ACC:74.538750%
Sat, 03 Jun 2023 03:46:04 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:49:12 INFO -------[Epoch]:60-------
Sat, 03 Jun 2023 03:49:12 INFO [Train] Loss:0.001475 , Train_Acc:98.661880%
Sat, 03 Jun 2023 03:49:12 INFO [Train] Loss_Open:0.000038 , Loss_Close:0.000129%
Sat, 03 Jun 2023 03:49:20 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:56.666668%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 03:49:20 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:52:29 INFO -------[Epoch]:61-------
Sat, 03 Jun 2023 03:52:29 INFO [Train] Loss:0.001755 , Train_Acc:98.792427%
Sat, 03 Jun 2023 03:52:29 INFO [Train] Loss_Open:0.000063 , Loss_Close:0.000142%
Sat, 03 Jun 2023 03:52:36 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:54.143650%   |  Close_ACC:76.666664%
Sat, 03 Jun 2023 03:52:36 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:55:41 INFO -------[Epoch]:62-------
Sat, 03 Jun 2023 03:55:41 INFO [Train] Loss:0.000706 , Train_Acc:98.955612%
Sat, 03 Jun 2023 03:55:41 INFO [Train] Loss_Open:0.000039 , Loss_Close:0.000047%
Sat, 03 Jun 2023 03:55:50 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:53.888889%   |  Close_ACC:77.859779%
Sat, 03 Jun 2023 03:55:50 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 03:58:56 INFO -------[Epoch]:63-------
Sat, 03 Jun 2023 03:58:56 INFO [Train] Loss:0.000513 , Train_Acc:99.086166%
Sat, 03 Jun 2023 03:58:56 INFO [Train] Loss_Open:0.000039 , Loss_Close:0.000027%
Sat, 03 Jun 2023 03:59:04 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:55.248619%   |  Close_ACC:77.037033%
Sat, 03 Jun 2023 03:59:04 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:02:10 INFO -------[Epoch]:64-------
Sat, 03 Jun 2023 04:02:10 INFO [Train] Loss:0.000490 , Train_Acc:98.988251%
Sat, 03 Jun 2023 04:02:10 INFO [Train] Loss_Open:0.000037 , Loss_Close:0.000026%
Sat, 03 Jun 2023 04:02:19 INFO [Validate] Val_Acc:67.184036%  |  Open_ACC:52.486191%   |  Close_ACC:77.037033%
Sat, 03 Jun 2023 04:02:19 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:05:25 INFO -------[Epoch]:65-------
Sat, 03 Jun 2023 04:05:25 INFO [Train] Loss:0.000571 , Train_Acc:99.086166%
Sat, 03 Jun 2023 04:05:25 INFO [Train] Loss_Open:0.000042 , Loss_Close:0.000031%
Sat, 03 Jun 2023 04:05:34 INFO [Validate] Val_Acc:66.962303%  |  Open_ACC:52.777779%   |  Close_ACC:76.383766%
Sat, 03 Jun 2023 04:05:34 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:08:42 INFO -------[Epoch]:66-------
Sat, 03 Jun 2023 04:08:42 INFO [Train] Loss:0.000665 , Train_Acc:98.890343%
Sat, 03 Jun 2023 04:08:42 INFO [Train] Loss_Open:0.000045 , Loss_Close:0.000039%
Sat, 03 Jun 2023 04:08:51 INFO [Validate] Val_Acc:67.184036%  |  Open_ACC:52.222225%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 04:08:51 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:11:57 INFO -------[Epoch]:67-------
Sat, 03 Jun 2023 04:11:57 INFO [Train] Loss:0.000599 , Train_Acc:99.020889%
Sat, 03 Jun 2023 04:11:57 INFO [Train] Loss_Open:0.000032 , Loss_Close:0.000041%
Sat, 03 Jun 2023 04:12:06 INFO [Validate] Val_Acc:67.184036%  |  Open_ACC:53.038677%   |  Close_ACC:76.666664%
Sat, 03 Jun 2023 04:12:06 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:15:13 INFO -------[Epoch]:68-------
Sat, 03 Jun 2023 04:15:13 INFO [Train] Loss:0.000862 , Train_Acc:98.988251%
Sat, 03 Jun 2023 04:15:13 INFO [Train] Loss_Open:0.000038 , Loss_Close:0.000065%
Sat, 03 Jun 2023 04:15:22 INFO [Validate] Val_Acc:66.075386%  |  Open_ACC:53.333336%   |  Close_ACC:74.538750%
Sat, 03 Jun 2023 04:15:22 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:18:29 INFO -------[Epoch]:69-------
Sat, 03 Jun 2023 04:18:29 INFO [Train] Loss:0.001891 , Train_Acc:98.727158%
Sat, 03 Jun 2023 04:18:29 INFO [Train] Loss_Open:0.000044 , Loss_Close:0.000169%
Sat, 03 Jun 2023 04:18:38 INFO [Validate] Val_Acc:67.405762%  |  Open_ACC:55.248619%   |  Close_ACC:75.555557%
Sat, 03 Jun 2023 04:18:38 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:21:44 INFO -------[Epoch]:70-------
Sat, 03 Jun 2023 04:21:44 INFO [Train] Loss:0.000579 , Train_Acc:99.020889%
Sat, 03 Jun 2023 04:21:44 INFO [Train] Loss_Open:0.000032 , Loss_Close:0.000039%
Sat, 03 Jun 2023 04:21:52 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:57.222225%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 04:21:52 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:24:59 INFO -------[Epoch]:71-------
Sat, 03 Jun 2023 04:24:59 INFO [Train] Loss:0.000436 , Train_Acc:99.151436%
Sat, 03 Jun 2023 04:24:59 INFO [Train] Loss_Open:0.000027 , Loss_Close:0.000027%
Sat, 03 Jun 2023 04:25:08 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:58.333336%   |  Close_ACC:76.383766%
Sat, 03 Jun 2023 04:25:08 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:28:12 INFO -------[Epoch]:72-------
Sat, 03 Jun 2023 04:28:12 INFO [Train] Loss:0.000483 , Train_Acc:99.053528%
Sat, 03 Jun 2023 04:28:12 INFO [Train] Loss_Open:0.000031 , Loss_Close:0.000029%
Sat, 03 Jun 2023 04:28:20 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:55.801105%   |  Close_ACC:77.777779%
Sat, 03 Jun 2023 04:28:20 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:31:26 INFO -------[Epoch]:73-------
Sat, 03 Jun 2023 04:31:26 INFO [Train] Loss:0.000495 , Train_Acc:99.086166%
Sat, 03 Jun 2023 04:31:26 INFO [Train] Loss_Open:0.000038 , Loss_Close:0.000026%
Sat, 03 Jun 2023 04:31:35 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:56.353592%   |  Close_ACC:77.407410%
Sat, 03 Jun 2023 04:31:35 INFO [Result] The best acc is 69.179604% at epoch 33
Sat, 03 Jun 2023 04:34:40 INFO -------[Epoch]:74-------
Sat, 03 Jun 2023 04:34:40 INFO [Train] Loss:0.000484 , Train_Acc:99.249352%
Sat, 03 Jun 2023 04:34:40 INFO [Train] Loss_Open:0.000031 , Loss_Close:0.000030%
Sat, 03 Jun 2023 04:34:48 INFO [Validate] Val_Acc:69.401329%  |  Open_ACC:56.906078%   |  Close_ACC:77.777779%
Sat, 03 Jun 2023 04:34:50 INFO [Result] The best acc is 69.401329% at epoch 74
Sat, 03 Jun 2023 04:37:51 INFO -------[Epoch]:75-------
Sat, 03 Jun 2023 04:37:51 INFO [Train] Loss:0.000482 , Train_Acc:99.347260%
Sat, 03 Jun 2023 04:37:51 INFO [Train] Loss_Open:0.000033 , Loss_Close:0.000028%
Sat, 03 Jun 2023 04:38:00 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:55.000000%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 04:38:00 INFO [Result] The best acc is 69.401329% at epoch 74
Sat, 03 Jun 2023 04:41:04 INFO -------[Epoch]:76-------
Sat, 03 Jun 2023 04:41:04 INFO [Train] Loss:0.000676 , Train_Acc:99.020889%
Sat, 03 Jun 2023 04:41:04 INFO [Train] Loss_Open:0.000030 , Loss_Close:0.000050%
Sat, 03 Jun 2023 04:41:13 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:55.555557%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 04:41:13 INFO [Result] The best acc is 69.401329% at epoch 74
Sat, 03 Jun 2023 04:44:18 INFO -------[Epoch]:77-------
Sat, 03 Jun 2023 04:44:18 INFO [Train] Loss:0.000522 , Train_Acc:99.020889%
Sat, 03 Jun 2023 04:44:18 INFO [Train] Loss_Open:0.000040 , Loss_Close:0.000027%
Sat, 03 Jun 2023 04:44:26 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:54.444447%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 04:44:26 INFO [Result] The best acc is 69.401329% at epoch 74
Sat, 03 Jun 2023 04:47:28 INFO -------[Epoch]:78-------
Sat, 03 Jun 2023 04:47:28 INFO [Train] Loss:0.000429 , Train_Acc:99.184074%
Sat, 03 Jun 2023 04:47:28 INFO [Train] Loss_Open:0.000024 , Loss_Close:0.000029%
Sat, 03 Jun 2023 04:47:37 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:57.222225%   |  Close_ACC:76.383766%
Sat, 03 Jun 2023 04:47:37 INFO [Result] The best acc is 69.401329% at epoch 74
Sat, 03 Jun 2023 04:50:36 INFO -------[Epoch]:79-------
Sat, 03 Jun 2023 04:50:36 INFO [Train] Loss:0.000580 , Train_Acc:98.988251%
Sat, 03 Jun 2023 04:50:36 INFO [Train] Loss_Open:0.000042 , Loss_Close:0.000032%
Sat, 03 Jun 2023 04:50:45 INFO [Validate] Val_Acc:69.623062%  |  Open_ACC:57.458565%   |  Close_ACC:77.777779%
Sat, 03 Jun 2023 04:50:47 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 04:53:52 INFO -------[Epoch]:80-------
Sat, 03 Jun 2023 04:53:52 INFO [Train] Loss:0.000767 , Train_Acc:99.086166%
Sat, 03 Jun 2023 04:53:52 INFO [Train] Loss_Open:0.000063 , Loss_Close:0.000037%
Sat, 03 Jun 2023 04:54:01 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:58.011051%   |  Close_ACC:76.666664%
Sat, 03 Jun 2023 04:54:01 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 04:57:01 INFO -------[Epoch]:81-------
Sat, 03 Jun 2023 04:57:01 INFO [Train] Loss:0.000860 , Train_Acc:98.890343%
Sat, 03 Jun 2023 04:57:01 INFO [Train] Loss_Open:0.000047 , Loss_Close:0.000058%
Sat, 03 Jun 2023 04:57:10 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:56.666668%   |  Close_ACC:77.490776%
Sat, 03 Jun 2023 04:57:10 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:00:13 INFO -------[Epoch]:82-------
Sat, 03 Jun 2023 05:00:13 INFO [Train] Loss:0.000805 , Train_Acc:98.988251%
Sat, 03 Jun 2023 05:00:13 INFO [Train] Loss_Open:0.000030 , Loss_Close:0.000064%
Sat, 03 Jun 2023 05:00:22 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:56.666668%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 05:00:22 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:03:26 INFO -------[Epoch]:83-------
Sat, 03 Jun 2023 05:03:26 INFO [Train] Loss:0.000719 , Train_Acc:99.086166%
Sat, 03 Jun 2023 05:03:26 INFO [Train] Loss_Open:0.000026 , Loss_Close:0.000058%
Sat, 03 Jun 2023 05:03:34 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:57.458565%   |  Close_ACC:77.037033%
Sat, 03 Jun 2023 05:03:34 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:06:35 INFO -------[Epoch]:84-------
Sat, 03 Jun 2023 05:06:35 INFO [Train] Loss:0.000568 , Train_Acc:99.053528%
Sat, 03 Jun 2023 05:06:35 INFO [Train] Loss_Open:0.000027 , Loss_Close:0.000041%
Sat, 03 Jun 2023 05:06:44 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:57.222225%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 05:06:44 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:09:47 INFO -------[Epoch]:85-------
Sat, 03 Jun 2023 05:09:47 INFO [Train] Loss:0.000528 , Train_Acc:99.118797%
Sat, 03 Jun 2023 05:09:47 INFO [Train] Loss_Open:0.000019 , Loss_Close:0.000042%
Sat, 03 Jun 2023 05:09:56 INFO [Validate] Val_Acc:69.623062%  |  Open_ACC:55.801105%   |  Close_ACC:78.888885%
Sat, 03 Jun 2023 05:09:56 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:12:54 INFO -------[Epoch]:86-------
Sat, 03 Jun 2023 05:12:54 INFO [Train] Loss:0.000466 , Train_Acc:99.086166%
Sat, 03 Jun 2023 05:12:54 INFO [Train] Loss_Open:0.000024 , Loss_Close:0.000032%
Sat, 03 Jun 2023 05:13:03 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:56.111111%   |  Close_ACC:75.276756%
Sat, 03 Jun 2023 05:13:03 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:16:05 INFO -------[Epoch]:87-------
Sat, 03 Jun 2023 05:16:05 INFO [Train] Loss:0.000469 , Train_Acc:98.922981%
Sat, 03 Jun 2023 05:16:05 INFO [Train] Loss_Open:0.000023 , Loss_Close:0.000033%
Sat, 03 Jun 2023 05:16:13 INFO [Validate] Val_Acc:68.514412%  |  Open_ACC:55.801105%   |  Close_ACC:77.037033%
Sat, 03 Jun 2023 05:16:13 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:19:13 INFO -------[Epoch]:88-------
Sat, 03 Jun 2023 05:19:13 INFO [Train] Loss:0.000647 , Train_Acc:99.053528%
Sat, 03 Jun 2023 05:19:13 INFO [Train] Loss_Open:0.000030 , Loss_Close:0.000047%
Sat, 03 Jun 2023 05:19:21 INFO [Validate] Val_Acc:67.627495%  |  Open_ACC:54.143650%   |  Close_ACC:76.666664%
Sat, 03 Jun 2023 05:19:21 INFO [Result] The best acc is 69.623062% at epoch 79
Sat, 03 Jun 2023 05:22:21 INFO -------[Epoch]:89-------
Sat, 03 Jun 2023 05:22:21 INFO [Train] Loss:0.000542 , Train_Acc:99.053528%
Sat, 03 Jun 2023 05:22:21 INFO [Train] Loss_Open:0.000024 , Loss_Close:0.000040%
Sat, 03 Jun 2023 05:22:30 INFO [Validate] Val_Acc:70.066521%  |  Open_ACC:58.333336%   |  Close_ACC:77.859779%
Sat, 03 Jun 2023 05:22:32 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:25:31 INFO -------[Epoch]:90-------
Sat, 03 Jun 2023 05:25:31 INFO [Train] Loss:0.000511 , Train_Acc:99.086166%
Sat, 03 Jun 2023 05:25:31 INFO [Train] Loss_Open:0.000033 , Loss_Close:0.000031%
Sat, 03 Jun 2023 05:25:40 INFO [Validate] Val_Acc:69.623062%  |  Open_ACC:55.555557%   |  Close_ACC:78.966789%
Sat, 03 Jun 2023 05:25:40 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:28:40 INFO -------[Epoch]:91-------
Sat, 03 Jun 2023 05:28:40 INFO [Train] Loss:0.001858 , Train_Acc:98.988251%
Sat, 03 Jun 2023 05:28:40 INFO [Train] Loss_Open:0.000060 , Loss_Close:0.000155%
Sat, 03 Jun 2023 05:28:48 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:56.666668%   |  Close_ACC:77.121773%
Sat, 03 Jun 2023 05:28:48 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:31:53 INFO -------[Epoch]:92-------
Sat, 03 Jun 2023 05:31:53 INFO [Train] Loss:0.000590 , Train_Acc:98.955612%
Sat, 03 Jun 2023 05:31:53 INFO [Train] Loss_Open:0.000036 , Loss_Close:0.000038%
Sat, 03 Jun 2023 05:32:01 INFO [Validate] Val_Acc:69.623062%  |  Open_ACC:59.668510%   |  Close_ACC:76.296295%
Sat, 03 Jun 2023 05:32:01 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:35:07 INFO -------[Epoch]:93-------
Sat, 03 Jun 2023 05:35:07 INFO [Train] Loss:0.000422 , Train_Acc:99.020889%
Sat, 03 Jun 2023 05:35:07 INFO [Train] Loss_Open:0.000028 , Loss_Close:0.000025%
Sat, 03 Jun 2023 05:35:16 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:58.888889%   |  Close_ACC:76.014763%
Sat, 03 Jun 2023 05:35:16 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:38:27 INFO -------[Epoch]:94-------
Sat, 03 Jun 2023 05:38:27 INFO [Train] Loss:0.000375 , Train_Acc:99.151436%
Sat, 03 Jun 2023 05:38:27 INFO [Train] Loss_Open:0.000018 , Loss_Close:0.000027%
Sat, 03 Jun 2023 05:38:36 INFO [Validate] Val_Acc:68.957870%  |  Open_ACC:56.906078%   |  Close_ACC:77.037033%
Sat, 03 Jun 2023 05:38:36 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:41:51 INFO -------[Epoch]:95-------
Sat, 03 Jun 2023 05:41:51 INFO [Train] Loss:0.000450 , Train_Acc:99.151436%
Sat, 03 Jun 2023 05:41:51 INFO [Train] Loss_Open:0.000030 , Loss_Close:0.000027%
Sat, 03 Jun 2023 05:42:00 INFO [Validate] Val_Acc:69.401329%  |  Open_ACC:57.222225%   |  Close_ACC:77.490776%
Sat, 03 Jun 2023 05:42:00 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:45:08 INFO -------[Epoch]:96-------
Sat, 03 Jun 2023 05:45:08 INFO [Train] Loss:0.000534 , Train_Acc:99.184074%
Sat, 03 Jun 2023 05:45:08 INFO [Train] Loss_Open:0.000035 , Loss_Close:0.000032%
Sat, 03 Jun 2023 05:45:17 INFO [Validate] Val_Acc:69.179604%  |  Open_ACC:57.777779%   |  Close_ACC:76.752769%
Sat, 03 Jun 2023 05:45:17 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:48:26 INFO -------[Epoch]:97-------
Sat, 03 Jun 2023 05:48:26 INFO [Train] Loss:0.000414 , Train_Acc:99.249352%
Sat, 03 Jun 2023 05:48:26 INFO [Train] Loss_Open:0.000018 , Loss_Close:0.000031%
Sat, 03 Jun 2023 05:48:35 INFO [Validate] Val_Acc:68.292679%  |  Open_ACC:56.906078%   |  Close_ACC:75.925926%
Sat, 03 Jun 2023 05:48:35 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:51:41 INFO -------[Epoch]:98-------
Sat, 03 Jun 2023 05:51:41 INFO [Train] Loss:0.000477 , Train_Acc:99.118797%
Sat, 03 Jun 2023 05:51:41 INFO [Train] Loss_Open:0.000027 , Loss_Close:0.000032%
Sat, 03 Jun 2023 05:51:49 INFO [Validate] Val_Acc:68.736145%  |  Open_ACC:57.777779%   |  Close_ACC:76.014763%
Sat, 03 Jun 2023 05:51:49 INFO [Result] The best acc is 70.066521% at epoch 89
Sat, 03 Jun 2023 05:55:00 INFO -------[Epoch]:99-------
Sat, 03 Jun 2023 05:55:00 INFO [Train] Loss:0.000588 , Train_Acc:98.825066%
Sat, 03 Jun 2023 05:55:00 INFO [Train] Loss_Open:0.000025 , Loss_Close:0.000044%
Sat, 03 Jun 2023 05:55:08 INFO [Validate] Val_Acc:67.849220%  |  Open_ACC:57.222225%   |  Close_ACC:74.907753%
Sat, 03 Jun 2023 05:55:08 INFO [Result] The best acc is 70.066521% at epoch 89
